# Rによる教育データ分析入門（ver. 2020/05/19）


### ここに書かれたコードは、一部書籍と異なる場合があります。


########## Chapter 1 ##########

1 + 2

# 引き算
2 - 1
# 掛け算
2 * 3
# 割り算
4 / 2
# 累乗
3 ^ 4

# 以下の処理の実行結果は全て同じ（実行結果は省略）
1+2
1+ 2
1 +2
1 + 2
1     +     2

# 変数に代入
x <- 2

# 変数の中身の確認
x

# 代入と同時に変数の中身を確認
(x <- 2)

# 変数を使った計算
x + 1

# 別の変数を作成
y <- 3
# 変数同士の計算
x + y

# ベクトルの作成と代入
# c関数は，ベクトルを作成するための関数
x <- c(1, 2, 3, 4, 5)

# ベクトルの中身の確認
x
# ベクトルの長さ（要素数）の確認
length(x)

# ベクトルの3番目の要素だけを抽出
x[3]
# ベクトルの2番目から4番目の要素だけを抽出
x[2 : 4]

# ベクトルを使った計算
x * 2
# 別のベクトルを作成
y <- c(6, 7, 8, 9, 10)
# ベクトル同士の計算
x + y

# 行列の作成
# ベクトルの用意
z <- c(1, 2, 3, 4, 5, 6)
# 行列の形式に変換
matrix.1 <- matrix(z, nrow = 2, ncol = 3)
matrix.1

# matrix関数の引数byrowでTRUEを指定
matrix.2 <- matrix(z, nrow = 2, ncol = 3, byrow = TRUE)
matrix.2

# 行数の確認
nrow(matrix.2)
# 列数の確認
ncol(matrix.2)

# 行列を使った計算
matrix.2 + 1
# 別の行列を作成（matrix関数とc関数を入れ子にする）
matrix.3 <- matrix(c(7, 8, 9, 10, 11, 12), nrow = 2, ncol = 3, byrow = TRUE)
# 行列同士の計算
matrix.2 + matrix.3

# 行列の結合（行方向）
rbind(matrix.2, matrix.3)
# 行列の結合（列方向）
cbind(matrix.2, matrix.3)

# 元の行列
matrix.2
# 2行目・3列目の要素を抽出
matrix.2[2, 3]
# 2行目の要素全てを抽出
matrix.2[2, ]
# 3列目の要素全てを抽出
matrix.2[, 3]
# 2行目の要素以外の全てを抽出
matrix.2[-2, ]
# 3列目の要素以外の全てを抽出
matrix.2[, -3]

# 元の行列
matrix.2
# 行列の転置
t(matrix.2)

matrix.2
# 行ラベルの付与
rownames(matrix.2) <- c("X", "Y")
# 列ラベルの付与
colnames(matrix.2) <- c("A", "B", "C")
# ラベルの確認
matrix.2

# ベクトルの用意
ID <- c("S001", "S002", "S003", "S004", "S005")
Score <- c(75, 68, 82, 90, 78)
# データフレームの作成
df <- data.frame(ID, Score)
# 作成したデータフレームの確認
df
# データの型（クラス）を確認
class(df)
class(df[, 1])
class(df[, 2])

# データフレームから一部の列のデータを抽出
df$Score
# 以下の処理と同じ
df[, 2]

# 作業ディレクトリの確認
getwd()

# 作業ディレクトリの変更
# 以下は，「C」ドライブ直下の「Data」フォルダに変更する例
setwd("C:/Data")

# ファイルが作業ディレクトリにある場合
dat <- read.csv("data_ch1-1.csv", header = FALSE)
# ファイルが作業ディレクトリではなく，C:/Dataにある場合
dat <- read.csv("C:/Data/data_ch1-1.csv", header = FALSE)
dat <- read.csv(file.choose(), header = FALSE)
dat

# マウス操作でdata_ch1-1.csvを選択する場合
dat <- read.csv(file.choose(), header = FALSE)

# マウス操作でdata_ch1-2.csvを選択する場合
dat.2 <- read.csv(file.choose(), header = TRUE)
dat.2

# マウス操作でdata_ch1-3.csvを選択する場合
dat.3 <- read.csv(file.choose(), header = TRUE, row.names = 1)
dat.3

# ファイルへの書き出し（任意のファイル名を指定）
write.table(dat.3, "output.csv", row.names = TRUE, col.names = NA, sep = ",")

# パッケージのインストール（初回のみ）
install.packages("foreign", dependencies = TRUE)
# パッケージの読み込み
library("foreign")

# c関数のヘルプを参照
help(c)

########## Chapter 2 ##########

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch2.csvを選択
dat <- read.csv(file.choose(), header = TRUE)
# 読み込んだデータの冒頭の確認
head(dat)

# 行数と列数の確認
dim(dat)

# 平均値の計算（全員分の点数の総計を人数で割る）
sum(dat$score) / nrow(dat)

# 平均値の計算（mean関数）
mean(dat$score)

# 5名の平均点
x <- c(70, 75, 80, 85, 90)
mean(x)

# 5名の平均点（外れ値がある場合）
y <- c(0, 75, 80, 85, 90)
mean(y)

# 70，75，80，85，90の中央値
median(x)
# 0，75，80，85，90の中央値
median(y)

# 100名の学習者の期末試験結果の中央値
median(dat$score)

# 100名の学習者の期末試験結果の最頻値
score.mode <- names(which.max(table(dat$score)))
score.mode

# 「文字列」から「数値」に変換
as.numeric(score.mode)

# 個々の点数をとった学習者の数を集計
score.tab <- table(dat$score)
score.tab

# 100名の学習者の期末試験結果の最小値
min(dat$score)
# 100名の学習者の期末試験結果の最大値
max(dat$score)

# 最小値と最大値をまとめて計算
range(dat$score)

# データがばらついている範囲（最大値?最小値）
max(dat$score) - min(dat$score)

# 100名の学習者の期末試験結果の分散
var(dat$score)

# 100名の学習者の期末試験結果の標準偏差
sd(dat$score)

# 100名の学習者の期末試験結果の5値要約
quantile(dat$score)

# 100名の学習者の期末試験結果の要約統計量（5値要約，平均値）
summary(dat$score)

# パッケージのインストール（初回のみ）
install.packages("psych", dependencies = TRUE)
# パッケージの読み込み
library("psych")
# 100名の学習者の期末試験結果の要約統計量（データ数，平均値，標準偏差，中央値，調整平均，中央絶対偏差値，最小値，最大値，範囲，歪度，尖度，標準誤差）
describe(dat$score)

# データの平均値を計算
score.mean <- mean(dat$score)
score.mean
# データの標準偏差を計算
score.sd <- sd(dat$score)
score.sd
# データの標準得点を計算
(dat$score - score.mean) / score.sd

# データの標準得点を計算（scale関数を使用）
scale(dat$score)

# データの偏差値を計算
((dat$score - mean(dat$score)) / sd(dat$score)) * 10 + 50

# データの偏差値を計算（scale関数を使用）
scale(dat$score) * 10 + 50

# 歪度
skew(dat$score)
# 尖度
kurtosi(dat$score)

########## Chapter 3 ##########

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch3.csvを選択
dat <- read.csv(file.choose(), header = TRUE)
# 読み込んだデータの冒頭の確認
head(dat)
# 行数と列数の確認
dim(dat)
# クラス別の学習者数
table(dat$class)
# 担当教員別の学習者数
table(dat$prof)
# 男女別の学習者数
table(dat$sex)
# 学部別の学習者数
table(dat$faculty)
# scoreの記述統計量
summary(dat$score)

# 欠損値（NA）を含む行を削除
dat.2 <- na.omit(dat)
# 行数と列数の確認
dim(dat.2)
# scoreの記述統計量（欠損値を除外した場合）
summary(dat.2$score)

# データのコピー
dat.3 <- dat
# 欠損値を0に置換
dat.3$score[is.na(dat.3$score)] <- 0
# 行数と列数の確認
dim(dat.3)
# scoreの記述統計量（欠損値を0に置換した場合）
summary(dat.3$score)

# ヒストグラムの描画
hist(dat.2$score)

# ヒストグラムのタイトルと軸ラベルを変更
hist(dat.2$score, main = "Final Exam", xlab = "score", ylab = "number of students")

# ヒストグラムの色を変更
hist(dat.2$score, main = "Final Exam", xlab = "score", ylab = "number of students", col = "white")
# Rで使える色の確認
colors()

# パッケージのインストール（初回のみ）
install.packages("lattice", dependencies = TRUE)
# パッケージの読み込み
library("lattice")
# 男女別の得点分布の比較
histogram(‾ score | sex, data = dat.2)

# 学部別の得点分布の比較
histogram(‾ score | faculty, data = dat.2)

# シンプルな箱ひげ図の描画
boxplot(dat.2$score)

# 箱ひげ図の作成に用いられている要約統計量の確認
boxplot.stats(dat.2$score)

# 箱ひげ図のタイトルと色を変更
boxplot(dat.2$score, main = "Final Exam", col = "white")

# クラス別の箱ひげ図
boxplot(dat.2$score ‾ dat.2$class)

# 箱ひげ図の縦軸のスケールを変更
boxplot(dat.2$score ‾ dat.2$class, ylim = c(0, 100))

# ノッチを入れた箱ひげ図
boxplot(dat.2$score ‾ dat.2$class, ylim = c(0, 100), notch = TRUE)
boxplot(dat.2$score ‾ dat.2$class, ylim = c(0, 100), notch = FALSE)

# パッケージのインストール（初回のみ）
install.packages("beeswarm", dependencies = TRUE)
# パッケージの読み込み
library("beeswarm")
# 蜂群図の描画
beeswarm(dat.2$score ‾ dat.2$class, ylim = c(0, 100), pch = 16, cex = 0.5)

# 箱ひげ図に蜂群図を重ねて描画
boxplot(dat.2$score ‾ dat.2$class, ylim = c(0, 100))
beeswarm(dat.2$score ‾ dat.2$class, ylim = c(0, 100), pch = 16, cex = 0.5, add = TRUE)

# パッケージのインストール（初回のみ）
install.packages("gplots", dependencies = TRUE)
# パッケージの読み込み
library("gplots")
# 平均値±標準偏差のプロット
plotmeans(dat.2$score ‾ dat.2$class)

jpeg("plot1.jpeg", width = 1000, height = 1000) 
plotmeans(dat.2$score ‾ dat.2$class)
dev.off()

# 各クラスの平均値
tapply(dat.2$score, dat.2$class, mean)
# 各クラスの標準偏差
tapply(dat.2$score, dat.2$class, sd)

# パッケージの読み込み
library("psych")
# クラスごとの記述統計量
describeBy(dat.2$score, dat.2$class)

########## Chapter 4 ##########

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch4_1.csvを選択
dat <- read.csv(file.choose(), header = TRUE)
# 読み込んだデータの冒頭の確認
head(dat)
# 行数と列数の確認
dim(dat)
# 読み込んだ4列のデータのうちNAのある行を削除
dat.2 <- na.omit(dat)
# NAのある行を削除したデータの冒頭を確認
head(dat.2)
# NAのある行を削除したデータの行数と列数の確認
dim(dat.2)
# クラス別の学習者数
table(dat.2$class)
# クラス別の男女の学習者数
table(dat.2$class, dat.2$sex)

# パッケージの読み込み
library("lattice")
library("beeswarm")
# クラス別の得点分布の比較（ヒストグラム）
histogram(‾ score | class, data = dat.2)
# クラス別の得点分布の比較（箱ひげ図と蜂群図）
boxplot(dat.2$score ‾ dat.2$class, ylim = c(0, 100), main = "Result of the Exam", xlab = "class", ylab = "score")
beeswarm(dat.2$score ‾ dat.2$class, ylim = c(0, 100), pch = 16, add = TRUE)

# パッケージの読み込み
library("psych")
# クラスごとの記述統計量の計算
describeBy(dat.2$score, dat.2$class)

# 等分散性の検定
# パッケージのインストール（初回のみ）
install.packages("car", dependencies = TRUE)
# パッケージの読み込み
library("car")
leveneTest(dat.2$score, dat.2$class, center = mean)

# 独立したt検定
t.test(dat.2$score ‾ dat.2$class, var.equal=T)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch4_2.csvを選択
dat.3 <- read.csv(file.choose(), header = TRUE)
# 読み込んだデータの冒頭の確認
head(dat.3)

# 行数と列数の確認
dim(dat.3)
# preとpostの列に欠損値がないか確認（TRUEがあれば，欠損値がある）
table(is.na(dat.3[3 : 4]))
# 男女の学習者数
table(dat.3$sex)

# 事前・事後テストの結果を重ねたヒストグラム（col = rgbで半透明の指定）
hist(dat.3$pre, col = rgb(1, 0, 0, 0.5), xlim = c(30, 100), ylim = c(0, 15), main = "Overlapping Histogram", xlab = "score")
hist(dat.3$post, col = rgb(0, 0, 1, 0.5), add = TRUE)
# 箱ひげ図に個人の得点分布を重ねた蜂群図
score <- c(dat.3$pre, dat.3$post)
group <- factor(c(rep("pre", 30), rep("post", 30)), levels = c("pre","post"))
boxplot(score ‾ group, ylim = c(0, 100), main = "Result of the Pre-Post Test", xlab = "test", ylab = "score")
beeswarm(score ‾ group, ylim = c(0, 100), pch = 16, add = TRUE)

# 記述統計量の確認
describe(dat.3[, 3 : 4])

# 対応のあるt検定
t.test(dat.3$pre, dat.3$post, paired = TRUE)

# p値の指数表示を回避
options(scipen = 10)
2.813e-05
# 事前テストと事後テストの相関係数
cor(dat.3$pre, dat.3$post)

# パッケージのインストール（初回のみ）
install.packages("latticeExtra", dependencies = TRUE)
# パッケージの読み込み
library("lattice")
library("latticeExtra")
# 個別推移図（スパゲティ・プロット）
df <- data.frame(score, group)
df$indiv <- factor(c(rep(1 : nrow(dat.3)), rep(1 : nrow(dat.3))))
each <- xyplot(score ‾ group, group = indiv, type = c("l"), data = df, xlab = "test", ylab = "score")
all_mean <- c(mean(dat.3$pre), mean(dat.3$post))
fact <- factor(c("pre", "post"), levels = c("pre","post"))
all <- xyplot(all_mean ‾ fact, col = "black", lwd = 5, type = c("l"), data = df)
each + as.layer(all, axes = NULL)

# 横軸に事前テスト，縦軸に事後テストをプロットした散布図
plot(dat.3$pre, dat.3$post, las = 1, pch = 16, xlab = "pretest", ylab = "posttest", main = NA, xlim = c(0, 100), ylim = c(0, 100))
lines(par()$usr[1 : 2], par()$usr[3 : 4], lty = 3)

########## Chapter 5 ##########

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch5_1.csvを選択
dat <- read.csv(file.choose(), header = TRUE)
# 読み込んだデータの冒頭の確認
head(dat)
# 行数と列数の確認
dim(dat)
# クラス別の学習者数
table(dat$class)
# クラスごとの記述統計量の計算
library("psych")
describeBy(dat$score, dat$class)
# 等分散性の検定
library("car")
leveneTest(dat$score, dat$class, center = mean)

# パッケージの読み込み
library("beeswarm")
# 蜂群図の描画
boxplot(dat$score ‾ dat$class, col = "grey", ylim = c(0, 100), main = "3クラスの比較", xlab = "class", ylab = "score")
beeswarm(dat$score ‾ dat$class, ylim = c(0, 100), pch = 16, add = TRUE)

# 繰り返しのない一元配置分散分析
# ANOVA君のソースを読み込んでから実行
source("anovakun_485.txt")
anovakun(dat[, -1], "As", 3, holm = TRUE, eta = TRUE)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch5_2.csvを選択
dat.2 <- read.csv(file.choose(), header = TRUE)
# 読み込んだデータの冒頭の確認
head(dat.2)
# 行数と列数の確認
dim(dat.2)
# クラス別の学習者数
table(dat.2$class)

# 二元配置分散分析
anovakun(dat.2[, -1], "AsB", 2, 3, auto = TRUE, holm = TRUE, eta = TRUE)

# スタック形式に変更
x <- stack(dat.2[, 3 : 5])
# データフレームの作成
y <- data.frame(dat.2$class, x)
# 因子の型に変更
y$dat.2.class <- factor(y$dat.2.class)
# 水準の順序を指定
y$ind <- factor(y$ind, levels = c("pre", "post", "delayed"))
# データフレームの列名を変更
names(y) <- c("class", "score", "test")
# 交互作用確認プロット
interaction.plot(y$test, y$class, y$score, type = "b", pch = c(1, 2), 
                 xlab = "Test", ylab = "Score", trace.label = "Class")

########## Chapter 6 ##########

# サンプルサイズ，平均値，標準偏差を指定してデータを作成する関数
gendat <- function(n, mu = 0, sigma = 1)
{
  x <- rnorm(n)
  return((x - mean(x)) / sd(x) * sigma + mu)
}
# データセットAの作成（サンプルサイズ，平均値，標準偏差の順）
a <- gendat(50, 30.00, 10.00)
b <- gendat(50, 32.00, 10.00)
# データセットBの作成（サンプルサイズ，平均値，標準偏差の順）
x <- gendat(500, 30.00, 10.00)
y <- gendat(500, 32.00, 10.00)

# t検定（データセットA）
t.test(a, b)
# t検定（データセットB）
t.test(x, y)

# 描画のためのデータを用意（因子型に変換）
score.A <- c(a, b)
group.A <- factor(c(rep("1 (n = 50)", length(a)), rep("2 (n = 50)", length(b)))) 
score.B <- c(x, y)
group.B <- factor(c(rep("1 (n = 500)", length(x)), rep("2 (n = 500)", length(y))))
# グラフを2つ並べて表示する設定
par(mfrow = c(1, 2))
# パッケージの読み込み
library("beeswarm")
# 箱ひげ図と蜂群図の描画
boxplot(score.A ‾ group.A, ylim = c(0, 70), main = "データセットA", xlab = "指導法", ylab = "score")
beeswarm(score.A ‾ group.A, ylim = c(0, 70), pch = 16, cex = 0.5, add = TRUE)
boxplot(score.B ‾ group.B, ylim = c(0, 70), main = "データセットB", xlab = "指導法", ylab = "score")
beeswarm(score.B ‾ group.B, ylim = c(0, 70), pch = 16, cex = 0.5, add = TRUE)

# パッケージのインストール（初回のみ）
install.packages("compute.es", dependencies = TRUE)
# パッケージの読み込み
library("compute.es")
# データセットAの効果量算出
mes(mean(a), mean(b), sd(a), sd(b), n.1 = 50, n.2 = 50)
# データセットBの効果量算出
mes(mean(x), mean(y), sd(x), sd(y), n.1 = 500, n.2 = 500)

# 第4章の対応のないt検定のデータから効果量を計算
mes(60.24, 72.27, 15.81, 16.11, 33, 37)

# 第4章の対応のあるt検定のデータから効果量を計算
# 対応なしの場合のdの計算
res <- mes(67.33, 74.43, 9.66, 8.98, 30, 30)

# 式（6.2）を使用
# 事前テストと事後テストの相関係数は0.6487101
# res[, "d"]は効果量d
d.val <- res[, "d"] / sqrt(2 * (1 - 0.6487101))
# 95%信頼区間の計算
library("psych")
d.ci(d.val, n1 = 30)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch6-1.csvを選択
dat <- read.csv(file.choose(), header = TRUE)

head(dat)

# パッケージのインストール（初回のみ）
install.packages("coin", dependencies = TRUE)
# パッケージの読み込み
library("coin")

# パッケージの読み込み
library("lattice")
library("beeswarm")
# クラス別の得点分布の比較（ヒストグラム）
histogram(‾ score | class, data = dat)
# クラス別の得点分布の比較（箱ひげ図と蜂群図）
boxplot(dat$score ‾ dat$class, ylim = c(0, 100), main = NA, xlab = "class", ylab = "score")
beeswarm(dat$score ‾ dat$class, ylim = c(0, 100), pch = 16, add = TRUE)



# Mann-WhitneyのU検定
res <- wilcox_test(dat$score ‾ factor(dat$class), distribution = "exact")
res
# res@statistic@teststatisticは，上の結果のZ値と同じ
r <- abs(res@statistic@teststatistic) / sqrt(length(dat$score))
r
# 効果量rの95%信頼区間の算出
library("psych")
r.con(r, length(dat$score), p = .95, twotailed = TRUE)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch6-2.csvを選択
dat.2 <- read.csv(file.choose(), header = TRUE)
head(dat.2)
# coinパッケージのwilcoxsign_test関数を用いて
# Wilcoxonの符号付順位和検定
res.2.1 <- wilcoxsign_test(dat.2$pre ‾ dat.2$post, distribution = "exact")
res.2.1

# Wilcoxonの符号付順位和検定
# パッケージのインストール（初回のみ）
install.packages("exactRankTests", dependencies = TRUE)
# パッケージの読み込み
library("exactRankTests")
res.2 <- wilcox.exact(dat.2$pre, dat.2$post, paired = TRUE)
res.2

res.2.1 <- wilcoxsign_test(dat.2$pre ‾ dat.2$post, distribution = "exact")
res.2.1

# 効果量rの計算
z <- qnorm(1 - (res.2$p.value / 2))
r <- z / sqrt(length(dat.2$pre) * 2)
r
# 効果量rの95%信頼区間の算出
r.con(r, length(dat.2$pre * 2), p =.95, twotailed = TRUE)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch6-3.csvを選択
dat.3 <- read.csv(file.choose(), header = TRUE)
# Kruskal-Wallis検定
res.3 <- kruskal.test(dat.3$score ‾ factor(dat.3$class))
res.3
# 効果量rの計算
z.2 <- qnorm(1 - (res.3$p.value / 2))
r.2 <- abs(z.2) / sqrt(nrow(dat.3))
r.2
# 効果量rの95%信頼区間の算出
r.con(r.2, nrow(dat.3), p =.95, twotailed = TRUE)
# 多重比較
# 引数p.adjで"bonferroni"を指定すれば，Bonferroniの方法
pairwise.wilcox.test(dat.3[, 2], dat.3[, 1], p.adj = "holm", exact = FALSE, correct = FALSE)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch6-4.csvを選択
dat.4 <- read.csv(file.choose(), header = TRUE)
# Freedman検定（データを行列に変換）
res.4 <- friedman.test(as.matrix(dat.4))
res.4
# 効果量rの計算
z.3 <- qnorm(1 - (res.4$p.value / 2))
r.3 <- abs(z.3) / sqrt(nrow(dat.4))
r.3
# 効果量rの95%信頼区間の算出
r.con(r.3, nrow(dat.4), p =.95, twotailed = TRUE)
# 型の変更
dat.5 <- stack(dat.4) 
x <- dat.5[, 1]
y <- dat.5[, 2]
# 多重比較（引数pairedでTRUEを指定）
pairwise.wilcox.test(x, y, p.adj = "holm", exact = FALSE, paired = TRUE, correct = FALSE)

########## Chapter 7 ##########

# CSVファイルの読み込み
# data_ch7-1.csvを選択
dat <- read.csv(file.choose(), header = TRUE) 
# 1〜6列目のうちNAのある行を削除
dat.2 <- na.omit(dat[, 1 : 6])
# NAのある行を削除したデータの冒頭を確認
head(dat.2)
# midとend（5〜6列目）の記述統計
summary(dat.2[, 5 : 6])

# 中間試験と期末試験のPearsonの積率相関係数
cor(dat.2$mid, dat.2$end, method = "pearson")

# 相関係数の有意確率（無相関検定）や95%信頼区間の計算
cor.test(dat.2$mid, dat.2$end, method = "pearson")

# 対角線ありの散布図の作成
plot(dat.2$mid, dat.2$end, 
     # ドットの大きさを変更
     cex = 1.2,
     # x軸・y軸のラベルと範囲を変更，タイトルを表示
     xlab = "中間テスト得点", xlim = c(0, 100),
     ylab = "期末テスト得点", ylim = c(0, 100))
# 散布図に切片a = 0，傾きb = 1の直線を表示
abline(a = 0, b = 1, lty = 1)

# パッケージの読み込み
library("psych")
# 中間試験（5列目）と期末試験（6列目）の散布図を作成
pairs.panels(dat.2[, 5 : 6], 
             # 回帰直線（黒色）とその95%信頼区間を表示
             lm = TRUE, ci = TRUE, col = "black",
             # ヒストグラムの色を変更
             hist.col = "grey",
             # ドットのスタイルを変更
             pch = 21,
             # 有意な相関係数にアスタリスクを付ける
             stars = TRUE,
             # 平滑線（smooth）と相関円（ellipses）を描写しない
             smooth = FALSE, ellipses = FALSE)


# 学科F01だけで相関分析
cor(dat.2$mid[dat.2$faculty == "F01"], dat.2$end[dat.2$faculty == "F01"], method = "pearson")

# パッケージの読み込み
library("lattice")
# 中間試験と期末試験の散布図を学科別にプロット（実行結果は省略）
xyplot(mid ‾ end | faculty, data = dat.2,
       # 中間の点数が80点以上か否かで色分け，異なるマーカーを使用
       groups = mid >= 80, col = c("grey20", "grey40"),
       pch = c(1, 16), cex = c(1.0, 1.0),
       # 中間試験と期末試験の平均点ラインを描写
       abline = list(h = mean(dat.2$mid),v = mean(dat.2$end),
                     col = "grey"))
# F01‾F09の順番を並び替えることも可能
dat.2$faculty <- factor(dat.2$faculty, 
                        levels = c("F07", "F08", "F09", "F04", "F05", "F06",
                                   "F01", "F02", "F03"))
xyplot(mid ‾ end | faculty, data = dat.2,  
       groups = mid >= 80, col = c("grey20", "grey40"),
       pch = c(1, 16), cex = c(1.0, 1.0),
       abline = list(h = mean(dat.2$mid),v = mean(dat.2$end),
                     col = "grey"))

# 7〜9列目のうちNAのある行を削除
dat.3 <- na.omit(dat[, 7 : 9])
# Spearmanの相関係数を計算
cor(dat.3, method = "spearman")

# 3変数以上の組み合わせから相関係数の有意確率と95%信頼区間を計算
res <- corr.test(dat.3, method = "spearman")
print(res, short = FALSE)

# 散布図
plot(dat.3)

# クロス集計表の作成
ques <- xtabs( ‾ manzoku + rikai, data = dat.3)
ques
# パッケージの読み込み
library("gplots")
# 気球グラフのプロット
balloonplot(ques)

# CSVファイルの読み込み
# data_ch7-2.csvを選択
dat.4 <- read.csv(file.choose(), header = TRUE) 
# 読み込んだデータの冒頭の確認
head(dat.4)

# 1列目を除いたデータからCronbachのα係数を計算
alpha(dat.4[, -1])

# パッケージの読み込み
library("RMeCab") 
# 分析データの読み込み
# data_ch7-3.csvを選択
dat.5 <- read.csv(file.choose(), header = FALSE)
# 形態素解析
RMC <- RMeCabDF(dat.5)
# 100名分の自由回答を結合
RMC.2 <- unlist(RMC)
# 結合したデータの冒頭を確認
head(RMC.2)

# 形態素解析の結果をデータフレームに変換
RMC.3 <- data.frame(RMC.2, names(RMC.2))
# 列名を編集
colnames(RMC.3) <- c("Word", "POS")
# データフレームの冒頭を確認
head(RMC.3)
# データフレームから名詞の行だけを抽出
noun <- RMC.3[RMC.3$POS == "名詞", ]
# 抽出した結果（冒頭の3つ）を確認
head(noun, 3)
# 名詞の頻度を集計
noun.list <- table(noun[, 1])
# 頻度の高い順に並び替え
noun.list.2 <- sort(noun.list, decreasing = TRUE)
# 並び替え結果をデータフレームに変換
noun.list.3 <- data.frame(noun.list.2)
# 列名を編集
colnames(noun.list.3) <- c("Word", "Freq")
# 頻度上位の名詞（冒頭の3つ）を確認
head(noun.list.3, 3)

# KWICコンコーダンスを作成する関数の定義
kwic.conc <- function(vector, word, span){
  word.vector <- vector  # 分析対象とするベクトルを指定
  word.positions <- which(word.vector == word)  # 分析対象とする単語の出現位置を特定
  context <- span  # 単語の文脈を左右何語ずつ表示するかを指定
  # 用例を検索
  for(i in seq(word.positions)) { 
    if(word.positions[i] == 1) {
      before <- NULL
    } else {
      start <- word.positions[i] - context
      start <- max(start, 1)
      before <- word.vector[start : (word.positions[i] - 1)]
    }
    end <- word.positions[i] + context
    after <- word.vector[(word.positions[i] + 1) : end]
    after[is.na(after)] <- ""
    keyword <- word.vector[word.positions[i]]
    # 用例を表示
    cat("--------------------", i, "--------------------", "¥n")
    cat(before, "[", keyword, "]", after, "¥n")
  }
}

# 「教室」の用例検索
kwic.conc(RMC.2, "教室", 5)

########## Chapter 8 ##########

# CSVファイルの読み込み
# data_ch8-1.csvを選択
dat <- read.csv(file.choose(), header = TRUE, row.names = 1)
# 欠損値（NA）の有無を確認
subset(dat, complete.cases(dat) == FALSE)
# 中間（1列目）と期末（2列目）の成績を抽出し，NAを含む行を削除
dat.2 <- na.omit(dat[, 1 : 2])
# 中間と期末の成績を抽出し，NAを含む行を削除したデータの冒頭を確認
head(dat.2)
plot(dat.2, xlim = c(0, 100), ylim = c(0, 100), xlab = "中間試験", ylab = "期末試験")

# Mahalanobisの距離
d <- mahalanobis(dat.2, apply(dat.2, 2, mean), cov(dat.2))
# データの行数と列数の計算
n <- nrow(dat.2)
v <- ncol(dat.2)
# 外れ値の検出
out <- n * (n - v) / ((n ^ 2 - 1) * v) * d > qf(0.9, n, v)
# 散布図に外れ値を表示
plot(dat.2, pch = ifelse(out, 16, 21), xlim = c(0, 100), ylim = c(0, 100), xlab = "中間試験", ylab = "期末試験")
# 外れ値の行番号とラベルを表示
text(dat.2[out, ] - 3, labels = paste(which(out), ":", rownames(dat.2)[out]))
# 外れ値の除外
dat.3 <- dat.2[-which(out == TRUE), ]

# 単回帰モデル（結果変数 ‾ 予測変数）
model.1 <- lm(end ‾ mid, data = dat.3)
summary(model.1)

# 回帰直線の可視化
plot(dat.3, xlim = c(0, 100), ylim = c(0, 100), xlab = "中間試験", ylab = "期末試験")
abline(model.1)

dat.3z <- scale(dat.3)
dat.3z <- data.frame(dat.3z)
attach(dat.3z)
model.1z <- lm(end ‾ mid, data = dat.3z)
summary(model.1z)
cor.test(end, mid)

# 傾きと切片の95%信頼区間
confint(model.1, level = 0.95)
# 新しいデータ（0点から100点まで1点刻み）を用意
new <- data.frame(mid = seq(0, 100, 1))
# 95%信頼区間の可視化
confidence <- predict(model.1, newdata = new, interval = 'confidence', level = 0.95)
lines(new$mid, confidence[, 2], lty = 3)
lines(new$mid, confidence[, 3], lty = 3)

# 中間試験が60点の場合の期末試験の点数の予測
pred <- predict(model.1, newdata = new, interval = 'prediction', level = 0.95)
pred[60, ]
# 予測区間の可視化
plot(dat.3, xlim = c(0, 100), ylim = c(0, 100), xlab = "中間試験", ylab = "期末試験")
abline(model.1)
lines(new$mid, pred[, 2], lty = 2)
lines(new$mid, pred[, 3], lty = 2)

# 残差の等分散性と正規性のプロット
par(mfcol = c(1, 2))
plot(model.1, which = c(1, 2))

# 分析データの準備
# CSVファイルの読み込み
# data_ch8-1.csvを選択
dat <- read.csv(file.choose(), header = TRUE, row.names = 1)
dat.4 <- na.omit(dat)
# パッケージのインストール（初回のみ）
install.packages("pequod", dependencies = TRUE)
# パッケージの読み込み
library("pequod")

# 外れ値の除外
d.2 <- mahalanobis(dat.4, apply(dat.4, 2, mean), cov(dat.4))
n.2 <- nrow(dat.4)
v.2 <- ncol(dat.4)
out.2 <- n.2 * (n.2 - v.2) / ((n.2 ^ 2 - 1) * v.2) * d.2 > qf(0.9, n.2, v.2)
dat.4[out.2, ]
dat.5 <- dat.4[-which(out.2 == TRUE), ]

# 重回帰モデル
model.2 <- lmres(end ‾ mid + quiz, data = dat.5)
summary(model.2)

# 回帰平面の作成
install.packages("scatterplot3d", dependencies = TRUE)
library(scatterplot3d)
plot3d <- scatterplot3d(dat.4$mid, dat.4$quiz, dat.4$end, type = "n", 
                        xlim = c(0, 100), ylim = c(0, 50), zlim = c(0, 100), angle = 25,
                        xlab = "中間試験", ylab = "期末試験", zlab = "小テスト")
plot3d$plane3d(lm(end ‾ mid + quiz, data = dat.4),
               lty.box = "solid", col = "grey", draw_polygon = TRUE, draw_lines = TRUE, 
               polygon_args = list(col = rgb(0.97, 0.97, 0.97, 0.97)))
orig <- plot3d$xyz.convert(dat.4$mid, dat.4$quiz, dat.4$end)
plane <- plot3d$xyz.convert(dat.4$mid, dat.4$quiz, fitted(lm(end ‾ mid + quiz, data = dat.4)))
i.negpos <- 1 + (resid(lm(end ‾ mid + quiz, data = dat.4)) > 0)
segments(orig$x, orig$y, plane$x, plane$y,
         lty = c(2, 1)[i.negpos])
wh1 <- resid(lm(end ‾ mid + quiz, data = dat.4)) > 0
wh2 <- resid(lm(end ‾ mid + quiz, data = dat.4)) < 0
segments(orig$x[wh1], orig$y[wh1], plane$x[wh1], plane$y[wh1], lty = 1)
plot3d$points3d(dat.4$mid[wh1], dat.4$quiz[wh1], dat.4$end[wh1], pch = 19)
plot3d$points3d(dat.4$mid[wh2], dat.4$quiz[wh2], dat.4$end[wh2], pch = 21)

# 交互作用の検討
model.3 <- lmres(end ‾ mid + quiz + mid : quiz, centered = c("mid", "quiz"), data = dat.5)
summary(model.3)

model.3.1 <- lmres(end ‾ mid + quiz + mid : quiz, data = dat.5)
summary(model.3.1)

# 単純傾斜の検定
eff.1 <- simpleSlope(model.3, pred = "mid", mod1 = "quiz")
summary(eff.1)
# 単純傾斜のプロット
PlotSlope(eff.1)

eff.3.1 <- simpleSlope(model.3.1, pred = "mid", mod1 = "quiz")
summary(eff.1)
PlotSlope(eff.3.1)

eff.2 <- simpleSlope(model.3, pred = "quiz", mod1 = "mid")
summary(eff.2)

# 単純傾斜のプロット
PlotSlope(eff.1)
PlotSlope(eff.2)

# 検定によるモデル選択
anova(model.1, model.2$Stepfin, model.3$Stepfin)

# 情報量基準によるモデル選択
AIC(model.1, model.2$Stepfin, model.3$Stepfin)

# 分析データの読み込み
# data_ch8-2.csvを選択
dat <- read.csv(file.choose(), row.names = 1, header = TRUE)
# 読み込んだデータの冒頭を確認
head(dat)
# 散布図の作成と回帰直線の描画
plot(dat$Hour, dat$TOEIC)
linear.model <- lm(TOEIC ‾ Hour, data = dat)
abline(linear.model)

# 個々の学習者の情報を表示した散布図
plot(dat$Hour, dat$TOEIC, pch = dat$School)

# 学校ごとに回帰分析
linear.model.2 <- lm(TOEIC[1 : 40] ‾ Hour[1 : 40], data = dat)
linear.model.3 <- lm(TOEIC[41 : 80] ‾ Hour[41 : 80], data = dat)
linear.model.4 <- lm(TOEIC[81 : 120] ‾ Hour[81 : 120], data = dat)
# 回帰直線の表示
abline(linear.model.2, lty = 1)
abline(linear.model.3, lty = 2)
abline(linear.model.4, lty = 3)

# パッケージのインストール（初回のみ）
install.packages("ICC", dependencies = TRUE)
# パッケージの読み込み
library("ICC")
# 級内相関
ICCest(TOEIC, Hour, data = dat)

# パッケージのインストール（初回のみ）
install.packages("lme4", dependencies = TRUE)
# パッケージの読み込み
library("lme4")
# マルチレベル分析
multilevel.model <- lmer(TOEIC ‾ Hour + (Hour | School), data = dat)
# マルチレベル分析の結果を確認
summary(multilevel.model)

# マルチレベル分析から得られた係数
fixef(multilevel.model)
# 通常の回帰分析から得られた係数
linear.model$coefficients
# 散布図上で比較
plot(dat$Hour, dat$TOEIC, pch = dat$School)
abline(fixef(multilevel.model), lty = 1)
abline(linear.model$coefficients, lty = 2)

# 勉強時間の影響を除いた学校間の点数比較
multilevel.model.2 <- lmer(TOEIC ‾ Hour + (1 | School), data = dat)
summary(multilevel.model.2)

########## Chapter 9 ##########

# CSVファイルの読み込み
# data_ch9-1.csvを選択
dat <- read.csv(file.choose(), header = TRUE)
# psychパッケージの読み込み
library("psych")
# 記述統計の確認 (1列目のstudentの列は分析に含めない)
describe(dat[, -1])

# KMOによるサンプリングの適切性指標を確認
KMO(dat[, -1])

# Bartlettの球面性検定
cortest.bartlett(cor(dat[, -1]), n = nrow(dat))

# 観測変数間の相関係数を確認する
pairs.panels(dat[, -1], lm = TRUE, density = FALSE)

# 因子数の決定（1）
# 固有値の計算
r.eigen <- eigen(cor(dat[, -1]))
print(r.eigen$values, digit = 2)

# スクリープロットの作成
plot(r.eigen$values, xlim = c(1, 9),  xaxp = c(1, 9, 8), type = "b", xlab = "因子の番号", ylab = "固有値")
abline(h = 1)

# 因子数の決定（2）
# MAP基準の確認
VSS(dat[, -1], n = nrow(dat), fm = "ml")

# 因子数の決定（3）
# 平行分析
fa.parallel(cor(dat[, -1]), fm = "ml", n.obs = nrow(dat), n.iter = 100)

# 最尤法・オブリミン回転による因子分析
r.fa <- fa(dat[, -1], nfactors = 3, fm = "ml", rotate = "oblimin")
print(r.fa, sort = TRUE, digits = 2)

# lavaanパッケージの読み込み
library("lavaan")
# 3因子構造のモデルを記述（''を忘れやすいので注意）
model.1 <- '
  LV.1 =‾ item8 + item9 + item4
  LV.2 =‾ item3 + item7
  LV.3 =‾ item2 + item1 + item6 '
# 確認的因子分析
fit.1 <- cfa(model.1, data = dat, estimator = "ML")
summary(fit.1, fit.measures = TRUE, standardized = TRUE)

# 適合度指標の検討
fitMeasures(fit.1)

# 2因子構造のモデルを記述
model.2 <- '
  LV.1 =‾ item8 + item9 + item4
  LV.2 =‾ item2 + item1 + item6 '
# 確認的因子分析
fit.2 <- cfa(model.2, data = dat, estimator = "ML")
summary(fit.2, fit.measures = TRUE, standardized = TRUE)

# model1とmodel2の比較
anova(fit.1, fit.2)

# 因子得点の計算
lavPredict(fit.2)

# 尺度得点の計算
LV.1 <- rowMeans(dat[, c(9, 10, 5)])
LV.2 <- rowMeans(dat[, c(3, 2, 7)])
cbind(LV.1, LV.2)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch9-2.csvを選択
dat.A <- read.csv(file.choose(), header = TRUE)
# data_ch9-3.csvを選択
dat.B <- read.csv(file.choose(), header = TRUE)

# パッケージのインストール（初回のみ）
install.packages("ltm", dependencies = TRUE)
# パッケージの読み込み
library("ltm") 
# 1パラメター（Rasch）モデルで分析
test.A <- rasch(dat.A[, -1])
test.B <- rasch(dat.B[, -1])

# 2つの図を1つにまとめて表示する設定
par(mfrow = c(1, 2))
# 項目特性曲線の作成
plot(test.A, type = "ICC", items = c(23, 24, 29))
# 項目情報量曲線の作成
plot(test.A, type = "IIC", items = c(23, 24, 29))

# 能力推定値の計算
theta.A <- factor.scores.rasch(test.A, resp.pattern = dat.A[, -1])
theta.B <- factor.scores.rasch(test.B, resp.pattern = dat.B[, -1])
A.theta <- theta.A$score.dat$z1
B.theta <- theta.B$score.dat$z1
# 計算結果の冒頭を確認
head(A.theta)
head(B.theta)

# 図9.6
raw　<-　rowSums(dat.A[, -1])
cbind(raw, A.theta)
par(ps = 20, mai = c(1, 1, 1, 1), mfrow = c(1, 2))
hist(A.theta, main = "", xlab = "能力推定値", ylab = "度数")
abline(v = mean(A.theta), lty = 2)
plot(raw, A.theta, pch = 1, xlab = "素点", ylab = "能力推定値", cex = 1.5)
abline(lm(A.theta ‾ raw), col = "black", lty = 2)

# 共通項目の難易度の平均値
(dffcltA.mean <- mean(test.A$coefficients[1:20, 1]))
(dffcltB.mean <- mean(test.B$coefficients[1:20, 1]))
# 変換式の作成
Intercept <- dffcltA.mean - dffcltB.mean
# テストB受験者の能力推定値をテストAに合わせる処理
B.adjusted <- B.theta + Intercept
# 等化前と等化後のテストＢ受験者の能力推定値の変化を箱ひげ図で可視化
boxplot(A.theta, B.theta, B.adjusted, names = c("テストA", "テストB（等化前）", "テストB（等化後）"), main = NA, xlab = NA, ylab = "能力推定値", col = "grey")

# CSVファイルの読み込み
# data_ch9-3.csvを選択
dat.C <- read.csv(file.choose(), header = TRUE)

# パッケージのインストール（初回のみ）
install.packages("mirt", dependencies = TRUE)
# パッケージの読み込み
library("mirt")
# 段階反応モデルで分析
test.C <- mirt(data = dat.C[, -1], model = 1, itemtype = "graded")
# 能力推定値の計算
C.theta <- fscores(test.C)
C.theta
# 項目特性曲線の作成
plot(test.C, type = 'trace', which.items = c(6, 10))

########## Chapter 10 ##########

# パッケージのインストール（初回のみ）
install.packages("semPlot", dependencies = TRUE)
# パッケージの読み込み
library("lavaan")
library("semPlot")

# CSVファイルの読み込み（data_ch10-1.csvを選択）
dat <- read.csv(file.choose(),fileEncoding = "shift-jis", header = TRUE)

# パス解析（逐次モデルの指定）
model.RM <- '
  興味関心 ‾ 学生対応 + 説明
  理解度 ‾ 説明 + 興味関心 '

# 分析と結果の表示
fit.RM <- sem(model.RM, data = dat, estimator = "ML")
summary(fit.RM, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# パス図の作成
semPaths(fit.RM, what = "stand", style = "lisrel", layout = "tree", rotation = 2, nCharNodes = 0, nCharEdges = 0, fade = FALSE, edge.width = 0.2, label.scale = FALSE, label.cex = 1.2, theme = 'gray', asize = 6.0, node.width = 2.0, curve = 2.0)

# CSVファイルの読み込み（data_ch10-2.csvを選択）
dat.2 <- read.csv(file.choose(),fileEncoding = "shift-jis", header = TRUE)

# MIMICモデルの指定
model.MIMIC <- '
  指導技術 =‾ 進み具合 + 興味関心 + 理解度
  指導技術 ‾ 学生対応 + 話し方 + 説明 '
# 分析と結果の表示
fit.MIMIC <- sem(model.MIMIC, data = dat.2, estimator = "ML")
summary(fit.MIMIC, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# パス図の作成
semPaths(fit.MIMIC, what = "stand", style = "lisrel", layout = "tree", rotation = 2, nCharNodes = 0, nCharEdges = 0, fade = FALSE, optimizeLatRes = TRUE, edge.width = 0.2, label.scale = FALSE, label.cex = 1.2, theme = 'gray', asize = 6.0, node.width = 1.5)

# CSVファイルの読み込み（data_ch10-3.csvを選択）
dat.3 <- read.csv(file.choose(), fileEncoding = "shift-jis", header = TRUE)

# 多重指標モデルの指定
model.MIC <- '
  授業満足度 =‾ item8 + item9 + item4
  指導技術 =‾ item2 + item1 + item6
  授業満足度 ‾ 指導技術 '
# 分析と結果の表示
fit.MIC <- sem(model.MIC, data = dat.3, estimator = "ML")
summary(fit.MIC, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# パス図の作成
semPaths(fit.MIC, what = "stand", style = "lisrel", layout = "tree", rotation = 2, nCharNodes = 0, nCharEdges = 0,  fade = FALSE, optimizeLatRes = TRUE, edge.width = 0.2, label.scale = FALSE, label.cex = 1.2, theme = 'gray', asize = 6.0, node.width = 1.5)

# CSVファイルの読み込み（data_ch10-4.csvを選択）
dat.4 <- read.csv(file.choose(),fileEncoding = "shift-jis", header = TRUE)

# 交差遅延モデル
model.CLM <- '
  単語力2 ‾ 単語力1 + 多読量1
  多読量2 ‾ 単語力1 + 多読量1 '
# 分析と結果の表示
fit.CLM <- sem(model.CLM, data = dat.4, estimator = "ML")
summary(fit.CLM, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# パス図の作成
semPaths(fit.CLM, what = "stand", style = "lisrel", layout = "tree2", rotation = 2, nCharNodes = 0, nCharEdges = 0, fade = FALSE, edge.width = 0.2, edge.label.position = 0.7, label.scale = FALSE, label.cex = 1.2, theme = 'gray', asize = 6.0,  node.width = 2.0)

# CSVファイルの読み込み（data_ch10-5.csvを選択）
dat.5 <- read.csv(file.choose(), fileEncoding = "shift-jis", header = TRUE)

# 潜在成長曲線モデルの指定
model.LGM <- '
  切片 =‾ 1 * 一学期 + 1 * 二学期 + 1 * 三学期 
  傾き =‾ 0 * 一学期 + 1 * 二学期 + 2 * 三学期 '

# 分析と結果の表示
fit.LGM <- growth(model.LGM, data = dat.5, estimator = "ML")
summary(fit.LGM, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# パス図の作成
semPaths(fit.LGM, title = FALSE, whatLabels = "est", style = "lisrel", layout = "tree", rotation = 1, nCharNodes = 0, nCharEdges = 0, fade = FALSE, optimizeLatRes = TRUE, edge.width = 0.2, edge.color = "black", label.scale = FALSE, label.cex = 1.2, theme = 'gray', asize = 6.0, node.width = 1.0)

# モデルの修正指標
modificationindices(fit.RM)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch10-6.csvを選択
dat <- read.csv(file.choose(), header = TRUE)
# 未受験者（NA）を削除
dat <- na.omit(dat)
# 素点を偏差値に換算
dat <- scale(dat[, -1]) * 10 + 50
# 読み込んだデータの冒頭の確認
head(dat)

# 関数の定義（コードは自動で読み込まれます）
source("C:/.../filename.txt")

# 最適なランクを探索
for(i in 2 : 6){
  print(i)
  r.LRT <- LRA(dat, i)
  AIC(r.LRT)
}

# 分析結果の確認
r.LRT <- LRA(dat, 5)
summary(r.LRT)

# ランクメンバーシッププロファイルの確認
r.LRT$rank
# ランクメンバーシッププロファイルの可視化
par(mfrow = c(1, 2))
plot(r.LRT$res[1, ], type = "b", xlab = "Rank")
plot(r.LRT$res[9, ], type = "b", xlab = "Rank")

########## Chapter 11 ##########

# CSVファイルの読み込み（ヘッダーと列名がある場合）
# data_ch11-1.csvを選択
dat <- read.csv(file.choose(), header = TRUE, row.names = 1)
# 読み込んだデータの冒頭の確認
head(dat)
# 行数と列数の確認
dim(dat)

# 各科目の平均点（＝列平均）を計算
colMeans(dat)
# 各学習者の平均点（＝行平均）を計算
rowMeans(dat)

# ユークリッド距離の計算
dat.d <- dist(dat)
# ユークリッド距離の計算結果の確認
dat.d

# ウォード法によるクラスターの作成
dat.hc <- hclust(dat.d, method = "ward.D2")
dat.hc

# 樹形図による可視化
plot(dat.hc)

# 樹形図における個々のデータを一番下にそろえて配置
plot(dat.hc, hang = -1)

# 個々のデータが含まれるクラスターの確認（クラスター数が2の場合）
cutree(dat.hc, k = 2)

# 樹形図による可視化
plot(dat.hc, hang = -1)
# 樹形図におけるクラスターを囲む四角形を表示（クラスター数が2の場合）
rect.hclust(dat.hc, k = 2)

# 分析データの形式を確認
class(dat)
# 分析データを行列に変換
dat.2 <- as.matrix(dat)
# 分析データの形式を再確認
class(dat.2)
# ヒートマップつきの樹形図の作成（ユークリッド距離，ウォード法）
heatmap(dat.2, cexCol = 0.5, hclustfun = function(x){hclust(x, method = "ward.D2")})

# 乱数の種を固定
set.seed(1)
# k-means法（クラスター数は2）
dat.km <- kmeans(dat, center = 2)

# k-means法によるクラスタリング結果の確認
dat.km$cluster

# パッケージの読み込み
library("cluster")
# k-means法によるクラスタリング結果の可視化
clusplot(dat, dat.km$cluster)

# k-means法によるクラスタリング結果の可視化（個々の学習者のIDを表示）
clusplot(dat, dat.km$cluster, labels = 2)

# Gap統計量の計算
set.seed(1)
dat.Gap <- clusGap(dat, kmeans, K.max = 5)
# 計算されたGap統計量の確認
dat.Gap

# Gap統計量とクラスター数の関係の可視化
plot(dat.Gap)

# CSVファイルの読み込み（ヘッダーがある場合）
# data_ch11-2.csvを選択
dat <- read.csv(file.choose(), header = TRUE)
# 読み込んだデータの冒頭の確認
head(dat)
# 読み込んだデータ（全体）の概要の確認
summary(dat)

# テストの合格者数と不合格者数を確認
table(dat$Grade)

# パッケージの読み込み
library("rpart")
# 決定木分析（Gradeを結果変数，それ以外を予測変数として指定）
rpart.result <- rpart(Grade ‾ ., data = dat)
# 分析結果の確認
rpart.result

# パッケージのインストール（初回のみ）
install.packages("partykit", dependencies = TRUE)
# パッケージの読み込み
library("partykit")
# 決定木の可視化
plot(as.party(rpart.result))

# 環境税アンケートの結果をベクトル形式で
z <- c(9, 40, 11, 17, 23)
# ラベルを付けます
names(z) <- c("大反対","反対","中立","賛成","大賛成")
z
# カイ二乗検定
result <- chisq.test(z)
result

# データを手入力して，ラベルを付けます
z2 <- matrix(c(3, 12, 12, 3, 9, 16, 8, 17), 
             ncol = 2, nrow = 4, byrow = T)
rownames(z2) <- c("国語","算数","社会","理科")
colnames(z2) <- c("男児","女児")
z2
# カイ2乗検定
result2 <- chisq.test(z2)
# 検定結果の確認
result2
# 標準化残差
result2$residuals
# 調整済み残差
result2$stdres
# p値の計算
pnorm(abs(result2$stdres), lower.tail = FALSE) * 2
#全体として差があったのでライアンの方法で多重比較
source("http://aoki2.si.gunma-u.ac.jp/R/src/p_multi_comp.R", encoding="euc-jp")
p.multi.comp(c(15, 15, 25, 25), c(3, 12, 9, 8), method="ryan")

summary(result2)
