par(mfcol=c(2,2))
plot(diff(log(x5202))*100,type="l")
plot(diff(log(x7272))*100,type="l")
plot(diff(log(x4927))*100,type="l")
plot(diff(log(x4502))*100,type="l")
detach(2)
#銘柄ごとの比較をしやすくするために、y軸方向の目盛りを合わせる
#最も振れ幅の大きいx5202の範囲を４つのグラフにplotする
attach(price4)
par(mfcol=c(2,2))
plot(diff(log(x5202))*100,type="l",ylim = range(diff(log(price4$x5202))*100))
plot(diff(log(x7272))*100,type="l",ylim = range(diff(log(price4$x5202))*100))
plot(diff(log(x4927))*100,type="l",ylim = range(diff(log(price4$x5202))*100))
plot(diff(log(x4502))*100,type="l",ylim = range(diff(log(price4$x5202))*100))
detach(2)
#視覚的なデータ分析は観測者の主観が入るので、より客観性を持たせるためにデータを定量化する
#分析対象のデータを「ある特定の分布から無作為に抽出された標本である」と考える
#得られた標本から母集団の特徴を推測する
#次に、標本数が与える影響について考える。標本は増えるほどいいが、同一条件での標本増加は難しい
#時系列データは市場変化などの影響で、同一条件での標本増加は難しい
#平均を求める
attach(return4)  #returnは収益率のデータ
mean(x5202)
mean(x7272)
mean(x4927)
mean(x4502)
detach(2)
#4銘柄のボラティリティを見る
#ボラティリティ＝価格変動幅の指標、これを調べることは母集団データの散らばり具合を見ることになる
#ボラティリティは標準偏差
#標準偏差（ボラティリティ）を求める
attach(return4)  #returnは収益率のデータ
sd(x5202)
sd(x7272)
sd(x4927)
sd(x4502)
detach(2)
#４銘柄のヒストグラムを書いてみる
attach(return4)  #returnは収益率のデータ
par(mfcol=c(2,2))
hist(x5202,main="板硝子",breaks = -10:10*5/3)
hist(x7272,main="ヤマハ",breaks = -10:10*5/3)
hist(x4927,main="ポーラ",breaks = -10:10*5/3)
hist(x4502,main="武田薬品",breaks = -10:10*5/3)
detach(2)
#他の銘柄との関係性を調べる　相関関係
attach(return4)  #returnは収益率のデータ
par(mfcol=c(1,1))
plot(x=x7272,y=x4502)
detach(2)
#相関係数
cor(return4$x7272, return4$x4502)
#１つ１つ実行するのは面倒。データフレーム化しておけば一発で散布図行列が出せる
plot(return4)
#同じく相関係数も一気に出せる(=相関行列)
cor(return4)
#統計的仮説検定について
#「データが正規分布に従う」＆「データが独立な標本である」の客観的な証明
#Rなどの計算ソフトではp値が算出され、その数値で帰無仮説の棄却を判断する
#Shapiro-Wilkの検定（正規性の検定）
#この検定の帰無仮説は「対象データ正規分布に従う」
shapiro.test(return4$x4927)
# W = 0.98323, p-value = 0.1419　となる。p値は14.19%である。
#有意水準を10%と考えた場合、帰無仮説は棄却されない
#４銘柄を検定にかけてみる
shapiro.test(return4$x5202) #  W = 0.92408, p-value = 4.19e-06
shapiro.test(return4$x7272) #  W = 0.99498, p-value = 0.9483
shapiro.test(return4$x4927) #  W = 0.98323, p-value = 0.1419
shapiro.test(return4$x4502) #  W = 0.9846, p-value = 0.1893
#検定の結果、x5202は0.001%未満であり帰無仮説が棄却される
#他の３銘柄は正規分布に従うと判断して良さそう
#独立な標本であるかの検定
#連の検定（runs test）…規則性の検定
#実施する内容は収益率の騰落に注目し、平均を上回るor下回るで判断
#runs testの帰無仮説は「並び方に規則性はない」
tmp = as.factor(return4$x7272 < mean(return4$x7272))
runs.test(tmp)  # Standard Normal = -0.17132, p-value = 0.864
#４銘柄検定してみる
tmp1 = as.factor(return4$x7272 < mean(return4$x7272))
tmp2 = as.factor(return4$x4502 < mean(return4$x4502))
tmp3 = as.factor(return4$x4927 < mean(return4$x4927))
tmp4 = as.factor(return4$x5202 < mean(return4$x5202))
runs.test(tmp1) # Standard Normal = -0.17132, p-value = 0.864
runs.test(tmp2) # Standard Normal = -0.12194, p-value = 0.9029
runs.test(tmp3) # Standard Normal =  1.6501,  p-value = 0.09892
runs.test(tmp4) # Standard Normal = -1.3706,  p-value = 0.1705
#有意水準を10%とすると、x4927ポーラだけが帰無仮説を棄却され、規則性があることになる
#厳密な意味としては「規則性がないとは言えない」
#時系列データでは＋とーの出現も時間に依拠していると考える。
#-----------------------------------------------------------------------------------
## 時間依存の発見
#-----------------------------------------------------------------------------------
#同じような傾向をとるデータは「独立標本」ではなく「ある傾向に従って抽出された」と考えるのが自然
#２つの銘柄の株価の収益率で前提条件を考えてみる
par(mfcol=c(2,2))
plot(X.price,type="l")
plot(X.return,type="l")
plot(Y.price,type="l",ylim = range(X.price))
plot(Y.return,type="l")
#価格の上下幅でみると大きな差があるが、収益率の挙動にも違いがある（振れ幅は同じくらい）
#収益率の挙動を深く読み解くために、株価の動きと関連づけてみる
#収益率の正負をわかりやすくするため、水準線をプロットする
par(mfcol=c(2,1))
plot(X.price,type="l")
plot(X.return,type="l")
abline(h=0,lty=3)     #ltyは線の種類（点線とか）
#0~40周辺は株価は上昇傾向、収益率は正の値が続く傾向
#60前後は株価が下落傾向、収益率は負の値が続く傾向
par(mfcol=c(2,1))
plot(Y.price,type="l",ylim = range(X.price))
plot(Y.return,type="l")
abline(h=0,lty=3)
#株価に上昇＆下降傾向はなく、収益率にも偏った値を取り続ける様子は見られない
#また、株価が下がった翌日には下がる、と行って特徴もない
par(mfcol=c(2,2))
hist(X.price)
hist(Y.price)
hist(X.return)
hist(Y.return)
#ヒストグラムや平均、標準偏差での比較は「データが同じ母集団からの標本」を前提にしている
#今回、そこから違いを見出すことができなかったので、時系列にその要素を求めていく
#-----------------------------------------------------------------------------------
## 時間依存と自己回帰モデル
#-----------------------------------------------------------------------------------
#銘柄Xは過去の値と同じような値がでやすう、という傾向があった
#確かめるために、縦軸にr(t)、横軸にr(t-1)のデータをプロットする
par(mfcol=c(1,2))
plot(x=X.return[1:99],y=X.return[2:100])
plot(x=Y.return[1:99],y=Y.return[2:100])
#自己相関係数を出してみる(rag1)
cor(X.return[1:99],X.return[2:100]) # 0.6353702
cor(Y.return[1:99],Y.return[2:100]) # 0.02348286
#各ragでの自己相関係数を算出する
acf(X.return,plot=F)
#ただし、corとは平均の算出方法が違うため、数値は一致しない
#横軸にrag数を、縦軸に自己相関係数の値をプロットしたものをコレログラムと呼ぶ
acf(X.return)
#０の上下の点線は自己相関係数が０である帰無仮説の元での９５％信頼区間を示す
#よって点線を超えたragの自己相関は有意水準５％で有意であると考えられる
#ただし、額面通りに６日前の固有の収益率が当日の収益率に関係しているとは判断できない
#自己相関係数の計算ではrag１の積み重ねによる間接的な関係が含まれているから
#例:rag1の自己相関係数には
#１、今日の値には昨日の値が関係する
#２、昨日の値には一昨日の値が関係する
#いずれも成り立つ、これを組み合わせると
#３、今日の値には、昨日を通じた一昨日の値が関係する
#これを推移律と呼ぶ。一方で
#４、一昨日の値が直接今日の値と関係する
#昨日の影響を排除した一昨日の関係を調べるためには偏自己相関係数を求める
acf(X.return, plot=F, type="partial")
#偏自己相関係数をこコレログラムにする
acf(X.return, plot=T, type="p")
#自己相関係数を有しているかは統計的仮説検定で計量的に算出することも可能
#Ljung-Box検定　→　帰無仮説：自己相関関係を有していない
Box.test(X.return, type = "L")  #X-squared = 41.02, df = 1, p-value = 1.507e-10
#p値は極めて低いため、自己相関関係を有していると判断できる
Box.test(Y.return, type = "L")  #X-squared = 0.056563, df = 1, p-value = 0.812
#銘柄Yは自己相関係数が存在しないと判断できる
#-----------------------------------------------------------------------------------
##時系列データの性質
#-----------------------------------------------------------------------------------
#時系列データの分析＝データの並び順に意味を見出す、と言える
#「独立に抽出された標本」という前提は使えない。
#各t時点mの確率変数R(t)が従う分布の特性を調べる、そのためには平均・分散・共分散が必要
#ただし各時点の平均が等しい、確率分布が等しいといい前提はないという点に注意
#つまり標本平均・標本分散は推定値として使えないということになる
#まず行うのは「データが同一の分布に従う」という前提で分析することになる
#ただし「全ての時点の確率分布が同一」という条件は強すぎるので、以下を前提にする
#　平均が一定
#　分散が一定
#　自己共分散がラグhのみに依存
# この３つの前提を満たすことを【弱定常性】と呼ぶ
mean(X.return)                                #平均
acf(X.return, plot=F, type="covariance")      #分散、自己共分散
#自己共分散を分散で割ると自己相関係数になる。比較しやすい
#ホワイトノイズ　：　平均が０、分散が一定値、自己共分散が０
#-----------------------------------------------------------------------------------
##自己回帰モデルの導入
#-----------------------------------------------------------------------------------
#「昨日と同じ値が出やすい」や「反発した値が出やすい」という事象は、確率変数間に関係性があることを示唆する
#その関係性を定式化すると
#R(t) = μ + φ(1)R(t-1) + ε(t)  ：　１時点前の自分自身を説明変量とした単回帰モデルであるので「自己回帰モデル」と呼ぶ
#ラグのことを「次数」と呼ぶ、εはホワイトノイズを仮定する
#ラグ１の場合の式であるが、これを利用してラグ２の計算をすることも可能
# r(t) = μ + φ(1)r(t-1) + e(t)　である
#しかし実際には自己回帰係数φ、切片μ、ホワイトノイズの分散σ**2は推定が必要
ar(X.return, aic=F,order.max = 1)
#aicは赤池情報量基準、order.maxで次数の最大値を決めその中で最も説明力のあるモデルを教えてくれる
#Coefficients: 0.631                             ：    φの値
#Order selected 1  sigma^2 estimated as  8.709   ：    σ**2の値
#μがないので、算出する
(1-0.631)*mean(X.return)                         #    μ = 0.08414278
#この結果から以下のモデルができる
# r(t) = 0.084 + 0.631*r(t-1) + e(t)
#Y銘柄は自己相関関係がなかったので、AICを用いてAR(1)かAR(0)のどちらが適しているかを算出
ar(Y.return, aic=T, order.max=1)  # Order selected 0  sigma^2 estimated as  14.32
#-----------------------------------------------------------------------------------
##定常性を満たさない場合の挙動はどうなるのか？
#-----------------------------------------------------------------------------------
#単位根過程
#定常性を有する場合には、平均と分散は発散せず　|φ1|<１　が条件となる。
#すなわち非定常な場合とは以下の４パターンである
#φ1>１   :　平均・分散ともにtが進むにつれ大きくなり、発散（指数関数的になる）
#φ1<-１  :　平均はtが進むにつれ大きくなり、tの偶奇により正負が交互に出現、分散はtが進むにつれ発散
　 #φ1=-１  :　平均はtの偶奇により正負が交互に出現、収束しない。分散はtが大きくなるにつれ大きくなり発散
#φ1=１   :　平均はμ=０の時は発散しない、分散はtが大きくなるにつれ大きくなり発散
#φ1=１となる時系列データを「単位根を持つ時系列データ」とよび、他の非定常時系列とは別に扱う
#単位根を持つ時系列データは非定常なので、定常な時系列データの分析手法を使えない。そのため先に検定が必要
#切片を０とし単位根を持つAR(1)モデルは
#R(t) = R(t-1) + ε(t)   となる。この式は
#R(t) = R(1) + ε(1) + ε(2) + ε(3) + …… + ε(t)   と書き換えることができる。ε(t)はホワイトノイズなので
#E(ε1) = E(ε2) = E(ε3) = …… =E(εt) = ０         となり
#E(Rt) = E(R1)                                  であることが言える
#平均は発散しない、時点tでの確率変数Rtは互いに独立で同一の正規分布に従う確率変数の和（ホワイトノイズの和）である
#そのため、観測されるデータの水準は確率的に変動する
#このような系列を「ランダムウォーク」と呼ぶ
#また、差分の形は
#R(t) - R(t-1) = ε(t)   となりホワイトノイズであるため定常性を有する確率変数列になる
#単位根を有するかの検定「Dickey-Fuller検定」　：　帰無仮説は「データ系列に単位根が存在する」
#ヤマハの株価を検定してみる
adf.test(price4$x7272)
#Dickey-Fuller = -2.9204, Lag order = 4, p-value = 0.1943
#alternative hypothesis: stationary
#p値=19.43%なので帰無仮説を棄却できず「単位根が存在する」になる
adf.test(return4$x7272)
#Dickey-Fuller = -4.9151, Lag order = 4, p-value = 0.01
#alternative hypothesis: stationary
#adf.test(return4$x7272) で:  p-value smaller than printed p-value
#p値は0.01%以下なので帰無仮説は棄却され「単位根が存在するとは言えない」となる
#ただし、発散していくような系列データではないため、そもそも「単位根が存在する」もしくは「定常性を満たす」のいずれか
#消去法的に「単位根が存在しない」と言える
#-----------------------------------------------------------------------------------
##自己回帰モデルの当てはめ残差を調べる
#-----------------------------------------------------------------------------------
#自己回帰モデルは誤差項にホワイトノイズを仮定しているので、実際のデータにモデルを当てはめた時の残差が同様の性質を持っていれば当てはめ成功
#この当てはまりがモデルの信頼度になるので必ず調べる
par(mfcol=c(2,1))
plot(data.log.return$x9041, type='l', ylab="Return")
plot(data.log.return$x9042, type='l', ylab="Return")
#この２つの系列に対して関数arを適用し自己回帰モデルを当てはめる
ar.fit1 = ar(data.log.return$x9041)  #aicを明示的に与えなければ、AICを使って最適な次数の自己回帰モデルを自動的に選び出してくれる
ar.fit2 = ar(data.log.return$x9042)
ar.fit1                              #Coefficients: 1  0.1591  Order selected 1  sigma^2 estimated as  1.64
ar.fit2                              #Coefficients: 1  0.1397  Order selected 1  sigma^2 estimated as  1.198
#どちらも次数１のARモデルが選ばれている
#コレログラムも見ておく
acf(data.log.return$x9041)  #次数１の自己相関は有意ではない
acf(data.log.return$x9042)  #次数１の自己相関は有意ではない
#２つの結果を見比べ、どのようなモデルを採用するかを決定していく
#次に残差を調べる、残差の平均と分散の性質を調べ、ホワイトノイズと同様の性質を持っている必要がある
#１、誤差平均を調べる---------------------------
#もし残差系列の間に時間依存の構造があるならば、誤差行の平均は
#E(εt) = f(t)   という時間を引数とした関数になっていることになる
#この場合、E(εt) = ０というホワイトノイズの仮定をを満たさないことになるのでモデルの当てはまりはよくない
#よって、まずは残差に時間依存構造がないかを調べる。時間依存の構図がないと以下の３つの特徴が見られる
#①残差のコレログラムを描いても意味のある自己相関は見当たらない
#②ARモデルを当てはめてもAICの基準で選択されるモデルの次数は０になる
#③Ljung-Box検定のような自己相関の検定でも「自己相関はない」という帰無仮説を棄却できない
#①コレログラムを描く
acf(ar.fit1$resid[-1])   #resid[-1]は、欠損となっているresidの１番目の要素を取り除く、という意味
acf(ar.fit2$resid[-1])
#目立って大きな自己相関は見当たらない
#②AICによる次数選択
ar(ar.fit1$resid[-1])$order  #０
ar(ar.fit2$resid[-1])$order  #０
#両方とも選択された次数は０
#③自己相関の有無（Ljung-Box検定）
Box.test(ar.fit1$resid[-1], type = "L")   #X-squared = 0.00058464, df = 1, p-value = 0.9807
Box.test(ar.fit2$resid[-1], type = "L")   #X-squared = 0.00029768, df = 1, p-value = 0.9862
#p値は両方0.9以上の値であるので帰無仮説を棄却できず「系列に自己相関はない」と判断できる
#３つの条件が揃ったので、誤差平均には時間的な依存構造は見られない、と結論づく
#２、誤差分散（残差の２乗系列）を調べる---------------------------
#誤差の分散が定数であるというホワイトノイズの過程が成立するならば、ε(t)^2の実現値である残差の２乗の系列には時間的な依存構造は決して見られないはず
#そこで残差の２乗の系列にも１と同様の条件確認を行う
#①残差のコレログラムを描いても意味のある自己相関は見当たらない
#②ARモデルを当てはめてもAICの基準で選択されるモデルの次数は０になる
#③Ljung-Box検定のような自己相関の検定でも「自己相関はない」という帰無仮説を棄却できない
#①コレログラムを描く
acf(ar.fit1$resid[-1]^2)   #resid[-1]は、欠損となっているresidの１番目の要素を取り除く、という意味
acf(ar.fit2$resid[-1]^2)
#ar.fit1ではいくつかの有意な自己相関が存在している。残差の分散が時間依存しているので、ホワイトノイズの仮定を満たしてない
#ar.fit2には有意な自己相関は見られない
#②AICによる次数選択
ar(ar.fit1$resid[-1]^2)
#Coefficients:
#    1        2        3        4        5        6        7
#0.2189   0.0177   0.0183   0.0248  -0.0864   0.0370   0.3461
#Order selected 7  sigma^2 estimated as  6.314
ar(ar.fit2$resid[-1]^2)
#Order selected 0  sigma^2 estimated as  3.52
#ar.fit1ではAR(7)が選ばれている　：　新たな誤差項をおく必要がある
#ar.fit2ではAR(0)が選ばれている　：　自己回帰構造のないモデルを採用してる
#③自己相関の有無（Ljung-Box検定）
Box.test(ar.fit1$resid[-1]^2, type = "L")   #X-squared = 7.9336, df = 1, p-value = 0.004853
Box.test(ar.fit2$resid[-1]^2, type = "L")   #X-squared = 0.00083385, df = 1, p-value = 0.977
#ar.fit1ではp値が0.0048　：　帰無仮説は棄却され「自己相関は存在する」
#ar.fit2ではp値が0.977　 ：　帰無仮説は棄却されず「自己相関は存在しない」
#このような時間依存している誤差の構造（残差の２乗に自己相関がある）は「分散不均一性」と呼ばれる
#分散不均一性を説明するモデルが「ARCHモデル」や「GARCHモデル」と呼ばれるモデル
#-----------------------------------------------------------------------------------
## ARCHモデル GARCHモデル
#-----------------------------------------------------------------------------------
#ARCHモデル  : t時点のボラティリティ　＝　過去のボラティリティ　＋　ω
#GARCHモデル : t時点のボラティリティ　＝　過去のボラティリティ　＋　過去の誤差の２乗　＋　ω
#ARCHモデル・GARCHモデルへの当てはめには２つの方法がある
#１、２段階推定　：　AR(1)の残差に対して当てはめる方法
#２、同時推定　　：　モデルのμの部分にAR(1)モデルを仮定し、モデルと同時にARの係数を推定する方法
#今回の場合、前段で「誤差行はホワイトノイズに従う」という誤った仮定の元でAR(1)モデルを当てはめたので捨てるべき
#２の方法で実施する
#①AR(1)＋ARCH(1)モデルの当てはめ---------------------------------------------------------------
arch.fit1=garchFit(~arma(1,0)+garch(1,0),      #モデルの指定、（）内はモデルのpやqに相当。garch(1,0)はGARCH(1,0)となる。ARMAは自己回帰移動平均モデル
data=data.log.return$x9041, #データの選択
trace=F)                    #推定の途中式を出力するかしないか（Trueで出力する）
arch.fit1
#結果
#Title: GARCH Modelling
#Call: garchFit(formula = ~arma(1, 0) + garch(1, 0), data = data.log.return$x9041, trace = F)
#Mean and Variance Equation: data ~ arma(1, 0) + garch(1, 0)
#<environment: 0x7fb650fddfd0> [data = data.log.return$x9041]
#Conditional Distribution: norm
#Coefficient(s):
#        mu         ar1       omega      alpha1
#   0.2365270  -0.0022778   1.1195896   0.3053496
#Std. Errors: based on Hessian
#Error Analysis:
#         Estimate  Std. Error  t value Pr(>|t|)
# mu      0.236527    0.107295    2.204   0.0275 *
# ar1    -0.002278    0.116571   -0.020   0.9844
# omega   1.119590    0.206116    5.432 　5.58e-08 ***
# alpha1  0.305350    0.159451    1.915   0.0555 .
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#Log Likelihood: -194.0714    normalized:  -1.617261
#データ分析のポイント---------------------------------------------------------------
#１、推定した係数の信頼度が高いこと　＝　係数についての仮説検定のp値が小さいこと。
#２、推定した標準化残差ν(t)が、仮定した分布（通常は標準正規分布）に従っていること
#-----------------------------------------------------------------------------------
#結果の意味（Error analytics部分）--------------------------------------------------
# Estimate      :　係数の推定値
# Std. Error    :　標準誤差
# t value       :　t値
# Pr(>|t|)      :　p値
# mu            :　μ　   ＝　切片
# ar1           :　φ   　＝　自己回帰係数
# omega         :　ω   　＝　定数
# alpha1        :　α(1)　＝　ラグ1の自己相関係数
#-----------------------------------------------------------------------------------
#結果の解釈-------------------------------------------------------------------------
#出力結果をAR(1)+ARCH(1)モデルに当てはめると
# r(t)    = 0.2365270 - 0.022778r(t-1) + ε(t)
# ε(t)    = σ(t)ν(t)
# ν(t)    ~ N(0,1)
# E(εt^2) = σ(t)^2 = 1.1195896 + 0.3053496ε(t-1)^2
#p値の判定から、AR(1)以外の推定値は信頼できる
#ボラティリティを図示
plot(Date[-1], arch.fit1@sigma.t^2, type="l", xlab="Date", ylab="Volatility")
#2012年の１２月以降（政権交代以降）ボラティリティが急激な上昇を見せている
#標準化残差ν(t)の評価
#もしAR(1)+ARCH(1)モデルがよく当てはまってるなら、推定した標準化残差ν(t)はモデルの仮定通り標準正規分布に従っているはず
#正規QQプロットを描いてみる : QQプロット＝理論値と実際の値を組みにした点をプロットする
qqnorm(arch.fit1@residuals/arch.fit1@sigma.t)
abline(0,1)
#正規性検定も行ってみる
shapiro.test(arch.fit1@residuals/arch.fit1@sigma.t)   #W = 0.97852, p-value = 0.05193
#p値が0.05と小さいので帰無仮説は棄却され「正規性はない」と判断できる
#-----------------------------------------------------------------------------------
#②出力結果をAR(1)+GARCH(1)モデルに当てはめ--------------------------------------------------------------
arch.fit2=garchFit(~arma(1,0)+garch(1,1),
data=data.log.return$x9041,
trace=F)
arch.fit2
#結果
#Title: GARCH Modelling
#Call: garchFit(formula = ~arma(1, 0) + garch(1, 1), data = data.log.return$x9041,trace = F)
#Mean and Variance Equation: data ~ arma(1, 0) + garch(1, 1)
#<environment: 0x7f984a38fed0> [data = data.log.return$x9041]
#Conditional Distribution: norm
#Coefficient(s):
#     mu       ar1     omega    alpha1     beta1
# 0.243296  0.146475  0.029693  0.079389  0.914535
#Std. Errors: based on Hessian
#Error Analysis:
#         Estimate  Std. Error  t value Pr(>|t|)
# mu       0.24330     0.10631    2.289   0.0221 *
# ar1      0.14648     0.09513    1.540   0.1236
# omega    0.02969     0.05160    0.575   0.5650
# alpha1   0.07939     0.04753    1.670   0.0949 .
# beta1    0.91454     0.06835   13.381   <2e-16 ***
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#Log Likelihood: -191.9937    normalized:  -1.599948
#結果の解釈-------------------------------------------------------------------------
#出力結果をAR(1)+ARCH(1)モデルに当てはめると
# r(t)    = 0.2330 - 0.14648r(t-1) + ε(t)
# ε(t)    = σ(t)ν(t)
# ν(t)    ~ N(0,1)
# E(εt^2) = σ(t)^2 = 0.02969 + 0.0739ε(t-1)^2 + 0.91454σ(t-1)^2
#p値の判定をみると推定制度が悪くなった印象。
#omegaのp値は非常に高いが、定数項であるので推定値が０と考えれば問題ではない
#総合するとどちらのモデルが良いか判断しにくい
#標準化残差ν(t)の評価
#もしAR(1)+GARCH(1)モデルがよく当てはまってるなら、推定した標準化残差ν(t)はモデルの仮定通り標準正規分布に従っているはず
#正規QQプロットを描いてみる : QQプロット＝理論値と実際の値を組みにした点をプロットする
qqnorm(arch.fit2@residuals/arch.fit2@sigma.t)
abline(0,1)
#正規性検定も行ってみる
shapiro.test(arch.fit2@residuals/arch.fit2@sigma.t)   #W = 0.97918, p-value = 0.0598
#p値が0.05と小さいので帰無仮説は棄却され「正規性はない」と判断できる
#結果的に、AR(1)+ARCH(1)もAR(1)+GARCH(1)もモデルとしては不十分であると考えられる。
#次に非正規な標準化残差を持つGARCHについて学ぶ
#-----------------------------------------------------------------------------------
##非正規な標準化残差を持つGARCH　〜Skew nomal分布を例に〜
#-----------------------------------------------------------------------------------
#ARCHモデルやGARCHモデルは標準化残差ν(t)として標準正規分布を想定している
#今回のデータはうまくフィットせずモデルとしては不十分である
#まずはどの程度不十分かを確認する
par(mfcol=c(1,1))
plot(density(arch.fit1@residuals/arch.fit1@sigma.t), main = "Density")
lines(-300:300/100, dnorm(-300:300/100,0,1), lty=2, col=2)
#赤線は標準正規分布密度関数、黒線がデータから指定した名称不明の確率密度関数
#推定値は標準正規分布よりも右に歪み、左に偏っているように見える
#この歪みが解消できれば精度向上しそう
#そのための方法は２つ
#標準化残差の従う分布を取り換える    :  今回はこっち
#GARCHモデルの構造自身に手を入れる   :  難しいので参考文献[4]で
#標準化残差の確率分布を取り換える
#ここでは、正規分布を左右に歪ませた分布である「skew normal分布」が有力な候補になる
arch.fit3 = garchFit(~garch(1,0), data = data.log.return$x9041, cond.dist = "snorm")
arch.fit3
##結果
#Title: GARCH Modelling
#Call: garchFit(formula = ~garch(1, 0), data = data.log.return$x9041,cond.dist = "snorm")
#Mean and Variance Equation:   data ~ garch(1, 0)
#<environment: 0x7fee4028ac90>
#[data = data.log.return$x9041]
#Conditional Distribution:  snorm
#Coefficient(s):
# mu       omega  alpha1     skew
# 0.24466  1.12865  0.27731  1.22818
#Std. Errors: based on Hessian
#Error Analysis:
#           Estimate  S Std. Error  t value  Pr(>|t|)
# mu        0.2447      0.1047      2.337    0.0194 *
# omega     1.1286      0.2033      5.551    2.84e-08 ***
# alpha1    0.2773      0.1454      1.907    0.0566 .
# skew      1.2282      0.1442      8.519    < 2e-16 ***
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#Log Likelihood: -193.1166    normalized:  -1.609305
#結果の解釈-------------------------------------------------------------------------
　#出力結果をAR(1)+ARCH(1)モデルに当てはめると
　#　 r(t)    = 0.2447 + ε(t)
　# 　ε(t)    = σ(t)ν(t)
　#　 ν(t)    ~ Skew Normal(0,1,1.2282)
　#　 E(εt^2) = σ(t)^2 = 1.12866 + 0.2773ε(t-1)^2
#どの係数をみても、有意水準10%でない数であると行ってよさそう
#標準化残差の解釈-------------------------------------------------------------------
#QQプロットを描いて標準化残差のskew normal分布への適合度を調べる
library(lattice)  #Rにはskew normal分布のためのQQプロット関数がないので汎用のQQプロット関数であるqqmathを使う
qqmath(~arch.fit3@residuals/arch.fit3@sigma.t,
distribution=function(p){qsnorm(p,xi=1.2282)},
abline=c(0,1), xlab="theoretical", ylab="sample")
#関数解説
　　#第１引数はデータ。ここでは標準化残差を指定している（残差を標準偏差で割る）
#第２引数は確率点を返す関数を指定している。歪みを示すパラメータxiに先ほどわかったskewの係数を入れている
#qsnormはfGarchパッケージの関数でskew normal分布の確率点を返す
#ほとんどのプロットが直線上に乗っていることがわかる
#次い統計的仮説検定似て軽量的な方法でぶんうの適合度を測る
#正規分布の場合は shapiro-wilk検定のようjな専用の仮説検定があるが、skew normalにはない
#そこで汎用的な適合度検定であるKolmogorov-Smirnov検定を使う
#Kolmogorov-Smirnov検定は２つの母集団の確率分布が等しいかどうかを、標本から経験分布関数を作りそれを比較して調べる
#Kolmogorov-Smirnov検定の帰無仮説は「２つの母集団の確率分布は等しい」です
ks.test(arch.fit3@residuals/arch.fit3@sigma.t, "psnorm", xi=1.2282)
#結果
# data:  arch.fit3@residuals/arch.fit3@sigma.t
# D = 0.062349, p-value = 0.7393
# alternative hypothesis: two-sided
#p値が0.739ということなので帰無仮説は棄却できない＝　標準化残差はskew normal分布に従っている
#補足：情報量基準をみたい時
arch.fit3@fit
install.packages("devtools")
devtools::install_github("evgeniikonev/simplepbar")
#-----------------------------------------------------------------------------------
##シミュレーション　〜リスク指標VaRを測る〜
#-----------------------------------------------------------------------------------
#株式投資において、もし１年ごの株式価値の分布が何らかの方法で作成できたとすれば、
#投資家はどの程度利益や損失が見込めるかを見当付けられ、投資判断がしやすい
#投資リスクを管理するフレームワークにVaR（Value at Risk）によるリスク計量法
#似たような方法で期待ショートフォールがある
#VaRの実装
spec = garchSpec(model = list(mu = arch.fit3@fit$coef[1], omega = arch.fit3@fit$coef[2],
alpha = arch.fit3@fit$coef[3], beta = 0,
skew = arch.fit3@fit$coef[4], cond.dist=c("snorm")))
PL = NULL;Price = data.price$x9041[121]
for (i in 1:10000){PL[i] = Price*exp(sum(garchSim(spec, 10))/100)}
PL = PL-Price
install.packages("devtools")
library("simplepbar")
library(tcltk)
install.packages("tcltk")
library(tcltk)
spec = garchSpec(model = list(mu = arch.fit3@fit$coef[1], omega = arch.fit3@fit$coef[2],
alpha = arch.fit3@fit$coef[3], beta = 0,
skew = arch.fit3@fit$coef[4], cond.dist=c("snorm")))
PL = NULL;Price = data.price$x9041[121]
for (i in 1:10000){PL[i] = Price*exp(sum(garchSim(spec, 10))/100)}
PL = PL-Price
plot(PL,type="bar")
plot(PL,type="hist")
PL
plot(PL, type="hist")
plot(PL, type="h")
hist(PL)
-sort(PL)[101]
source('~/Documents/R関連/timeseries/timeseries_first.R')
