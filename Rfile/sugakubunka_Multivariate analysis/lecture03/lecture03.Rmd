---
title: "第3回 : 非線形回帰"
output: html_notebook
---

# 1. 前準備
これまで解説した線形回帰は、目的変数を説明変数の1次式で表すような統計モデルのことでした。しかし、一般には目的変数と説明変数の間の関係が1次式でない（非線形である）ような場合も考えられます。このような場合に用いられる統計モデルが非線形回帰（nonlinear regression）です。今回は、非線形回帰にまつわる話題から、

* 非線形回帰の概要
* 多項式回帰
* べき乗回帰
* モデル選択

を解説します。

デモデータには、`R`言語にデフォルトで読み込まれている`mtcars`データセットを用います。このデータセットは、自動車の馬力と燃費の関係を記録したものです。

```{r}
# mtcarsデータセットの確認
dat <- mtcars[, c("hp", "mpg")]
head(x = dat, n = 5)
```

標本サイズと次元、変数の名前を確認しておきましょう。

```{r}
# 標本サイズ、次元、変数の名前の確認
str(dat)
```

今回は、馬力 `hp` を用いて燃費 `mpg` を説明するモデルを作ろうと思います。2変数の関係を把握するために散布図をかいておくことで、`馬力` と `燃費` との間は非線形な関係にあることが確認できます。

```{r}
# 散布図
plot(dat$hp, dat$mpg)
```


# 2. 非線形回帰

この節では、非線形回帰の概要を説明します。また、非線形回帰の具体例として、

* 多項式回帰
* べき乗回帰

を紹介します。

## 2.1 非線形回帰の概要
### A. 課題設定
データに $D$ 個の変数 $x_1,\cdots,x_D$ と $y$ が記録されているとき、変数 $y$ を変数 $x_1,\cdots,x_D$ の1次式ではない（非線形な）関数

\begin{align*}
y &= f(x_1,\cdots,x_D;\beta)+誤差
\end{align*}

で表現することで説明・予測できると仮定します。例えば、燃費を馬力で説明する式として

$$
\begin{align*}
燃費 &= \beta_0+\beta_1\times馬力+\beta_2\times馬力^2++誤差
\end{align*}
$$

という2次式や、

$$
\begin{align*}
燃費 &= \beta_1\times馬力^{\beta_2}+誤差
\end{align*}
$$

という式で説明できないかを検討していきましょう。前者のように説明変数の多項式で目的変数のとりうる値の傾向を表現するようなモデルを**多項式回帰**（polynomial regression）、後者のように説明変数の累乗とその定数倍で目的変数のとりうる値の傾向を表現するようなモデルを**べき乗回帰**（power regression）といいます。

### B. 出来ること
モデルに含まれる値が未知のパラメータ $\beta_1,\cdots,\beta_p$ を**偏回帰係数**（coefficient）といいます。これらの係数を推定することで、各説明変数の値が決まっているとき、目的変数の値はいくらと予測できるかを推定することができます。また、偏回帰係数の区間推定や統計的仮説検定を行うことができます。これについてはデモで例を交えながら解説します。

### C. 偏回帰係数の推定の仕組み
偏回帰係数の推定値 $\hat{\beta}$ は、データ全体で

* 偏回帰係数から決まる各標本点の予測値 $\hat{y}=f(x_1,\cdots,x_D;\hat{\beta})$
* 実測値 $y$

の差（**残差**といいます）の2乗 $(y-\hat{y})^2$ の平均値

\begin{align*}
l(\beta_0,\beta_1,\cdots, \beta_D) &= \frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y_i})^2
\end{align*}

が最小になるように決めます。これを**最小2乗法**（least squares method）といいます。非線形回帰とは、目的変数と説明変数の関係に偏回帰係数 $\beta$ で特徴付けられる関数 $f(x_1,\cdots,x_D;\beta)$ を仮定したとき、これを最小2乗法で推定する手法のことです。


## 2.2 多項式回帰のデモ
燃費 `mpg` を馬力 `hp` の2次式で表現するモデル、つまり

$$
\begin{align*}
燃費 &= \beta_0+\beta_1\times馬力+\beta_2\times馬力^2+誤差
\end{align*}
$$

を考えます。多項式回帰では、説明変数の値をそのまま用いると、大きい次数の項の値がとても大きくなったり小さくなったりすることで、計算機が数値的に不安定になることがあります。そのため、説明変数を事前に正規化（例えば標準化やmin-max正規化）することが一般的です。今回は、min-max正規化を採用します。

```{r}
# `hp`のmin-max正規化を`hp_scale`という名前で作る。
min_hp <- min(dat$hp)
max_hp <- max(dat$hp)
dat$hp_scale <- (dat$hp-min_hp) / (max_hp-min_hp)
head(x = dat, n = 5)
```


多項式回帰の場合、`R` 言語では次のように偏回帰係数を計算することができます。

```{r}
# 多項式回帰
result_deg2 <- lm(mpg ~ poly(hp_scale, degree = 2, raw = TRUE), 
                  data = dat)
summary(result_deg2)
```

また、得られた2次関数を散布図上に重ねてかくと、次のようになります。

```{r}
plot(dat$hp, dat$mpg)
lines(sort(dat$hp), predict(result_deg2)[order(dat$hp)]) 
```


**<font color = 59B9C6>問題</font>** : 以下の問いに答えてください。

(1) 推定によって得られた2次式を答えてください。

(2) 推定された結果に不自然な点があるかを検討してください。

**<font color = 59B9C6>解答</font>** : 

(1) 得られた3次式は以下の通りです。なお、式の中に現れる「馬力」は、min-max正規化を施した後の変数とします。

$$
\begin{align*}
燃費 &= -30.45+2.38\times馬力+0.08\times馬力^2+誤差
\end{align*}
$$

(2) 馬力が大きいほど燃費は必ず悪くなるとなると想定されます。しかしグラフからは、馬力が $250$ より大きくなると燃費が悪くなるという予測を与える式になっていることが確認できます。これが、このモデルの不自然な点です。■



## 2.3 べき乗回帰のデモ
燃費 `mpg` を馬力 `hp` の3次式で表現するモデル、つまり

$$
\begin{align*}
燃費 &= \beta_1\times馬力^{\beta_2}+誤差
\end{align*}
$$

を考えます。べき乗回帰では、偏回帰係数を推定するために、事前に初期値を決めておく必要があります。べき乗回帰における最小2乗法は**非線形最小2乗法**といって、予め決めた偏回帰係数の初期値から、より残差の2乗和が小さくなるような偏回帰係数の値へと更新していくような計算方法で、偏回帰係数の値を求めています。

この初期値を求める方法の一つとして、次のような線形回帰を先に計算しておきます。

```{r}
# 偏回帰係数の初期値の決定
lm(log(mpg) ~ log(hp), data = dat)
```

**<font color = 59B9C6>問題</font>** : 以下の問いに答えてください。

(1) べき乗回帰の式 $燃費 = \beta_1\times馬力^{\beta_2}+誤差$ の「誤差」を無視したとき、両辺の対数をとって得られる式を答えてください。

(2) 上の線形回帰の結果から、偏回帰係数の初期値をどう決めると良いかを考えてみてください。

**<font color = 59B9C6>解答</font>** : 

(1) $\log燃費=\log\beta_1+\beta_2\log馬力$

(2) `Intercept`は5.5454、`log(hp)`の偏回帰係数は-0.5301でした。(1)の結果から $\log\beta_1=5.5454$ とおいたとき $\beta_1=\exp(5.5454)$、$\beta_2=-0.5301$ と決めることができます。■

**Remark** :　なお目的変数を $\log燃費$、説明変数を $\log馬力$ とした線形回帰を式で表すと、$\log燃費=\alpha_1+\alpha_2\log馬力+誤差$ になります。指数をとると

$$
\begin{align*}
燃費 &= \exp\alpha_1\times馬力^{\alpha_2}\times\exp(誤差)\\
&= \beta_1\times馬力^{\beta_2}\times\exp(誤差)&\beta_1=\exp\alpha_1,\beta_2=\alpha_2とおく。
\end{align*}
$$
になるので、誤差のモデリングがべき乗回帰とは異なることが確認できます。つまり、`lm`関数で得られた推定結果はべき乗回帰そのものの結果ではなく、べき乗回帰は改めてやり直す必要があります。■


得られた初期値を用いて、べき乗回帰を計算してみましょう。`R` 言語では`nls`関数を用いて、べき乗回帰の偏回帰係数を計算することができます。

```{r}
# 多項式回帰
result_power <- nls(mpg ~ a*hp^b, 
                    data = dat, 
                    start = list(a = exp(5.5454), b = -0.5301), 
                    control = nls.control(maxiter = 100))
summary(result_power)
```

また、得られた関数を散布図上に重ねてかくと、次のようになります。

```{r}
plot(dat$hp, dat$mpg)
lines(sort(dat$hp), predict(result_power)[order(dat$hp)]) 
```

**<font color = 59B9C6>問題</font>** : 推定によって得られた関数を答えてください。

**<font color = 59B9C6>解答</font>** : 

得られた関数は以下の通りです。

$$
\begin{align*}
燃費 &= 272.12\times馬力^{-0.54}+誤差
\end{align*}
$$

# 2.3 モデル選択

## A. 赤池情報量規準
今回は、燃費 `mpg` を馬力 `hp` で表現する式を、多項式回帰とべき乗回帰の2通りで作りました。複数のモデルを作ったら、どちらのモデルを採用するかを検討しましょう。多項式回帰の節で出題した問題のように、各モデルの長所・短所を検討してモデルを選択することが大切です。しかし、場合によっては、それでもモデル選択に悩むことがあるでしょう。このようなとき、モデル選択の際にヒントになる指標の一つとして、未知のデータへの予測の精度を推定する方法だった赤池情報量規準を用いることができます。（第2回資料も参考にしてみてください。）

```{r}
# 多項式回帰とべき乗回帰の比較
AIC(result_deg2); AIC(result_power)
```

今回は、赤池情報量規準がより小さいべき乗回帰を採用するほうが良いのではないかと推定できます。


## B. 多項式回帰の次数の決定と過剰適合
多項式回帰の次数を決定する際、以下のように赤池情報量規準を各次数で計算し図にまとめることがあります。例えば、以下の図からは次数が$2$の場合が最も赤池情報量規準が小さいことが確認できます。


```{r}
# 多項式回帰の次数の決定
aic <- c()
for (d in 1:10) {    # 次数1から10までの多項式回帰を逐次計算する。
  result_poly <- lm(mpg ~ poly(hp_scale, degree = d, raw = TRUE), 
                    data = dat)
  aic[d] <- AIC(result_poly)
}

plot(1:10, aic, xlab = "degree", ylab = "AIC")
```

ところで、試しに次数10の多項式回帰を実行すると、以下のようにデータによくあてはまっているように見えます。それにも関わらず赤池情報量規準が次数2の場合より高い値になっているのはなぜでしょうか。

```{r}
# 次数10の多項式回帰（10次回帰ともいいます。）
result_deg10 <- lm(mpg ~ poly(hp_scale, degree = 10, raw = TRUE), 
                  data = dat)
plot(dat$hp, dat$mpg)
lines(sort(dat$hp), predict(result_deg10)[order(dat$hp)]) 
```

理由は、赤池情報量規準が「未知のデータへの予測の精度」を推定する方法だからです。手元のデータによくあてはまることと、まだ得られていない未知のデータによくあてはまることは異なります。前者が起こって後者が起こらないような現象を**過剰適合**（過学習, overfitting）、その逆を**過少適合**（未学習, underfitting）といいます。これらは特に、続・初級統計学で扱う後半の話題で、とても重要な話になっていきます。
