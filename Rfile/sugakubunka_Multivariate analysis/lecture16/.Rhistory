dat
?column_to_rownames
dat %>% column_to_rownames(var = "職業")
##### 階層クラスタリング #####
# ライブラリの読み込み
library(tidyverse)
# データの読み込み
dat <- read_csv("impression.csv",
locale = locale(encoding = "Shift-JIS"))
dat %>% column_to_rownames(var = "職業")
dat <- dat %>% column_to_rownames(var = "職業")
dat
# データの読み込み
dat <- read_csv("impression.csv",
locale = locale(encoding = "Shift-JIS"))
dat
View(res_pro)
# データの読み込み
dat <- read.csv("impression.csv",
fileEncoding = "Shift-JIS",
row.names = "職業")
dat
# データの正規化
dat_scaled <- scale(dat)
dat_scaled
# 階層クラスタリング
result <- agnes(x = dat_scaled,
metric = "euclidean",
method = "ward")
par(family = "ヒラギノ角ゴシック W3")
dend <- as.dendrogram(result)
plot(dend, main = "職業印象")
# 階層クラスタリング
result <- agnes(x = dat,
metric = "euclidean",
method = "ward")
par(family = "ヒラギノ角ゴシック W3")
dend <- as.dendrogram(result)
plot(dend, main = "職業印象")
?agnes
# 階層クラスタリング : 群平均法
result_average <- agnes(x = dat_scaled,
metric = "euclidean",
method = "average")
par(family = "ヒラギノ角ゴシック W3")
dend_average <- as.dendrogram(result_average)
plot(dend_average, main = "職業印象（群平均法）")
# 階層クラスタリング : 群平均法
result_average <- agnes(x = dat,
metric = "euclidean",
method = "average")
par(family = "ヒラギノ角ゴシック W3")
dend_average <- as.dendrogram(result_average)
plot(dend_average, main = "職業印象（群平均法）")
t(dat)
# 転置されたデータに対する階層クラスタリング
dat_T <- t(dat)
dat_T_scaled <- scale(dat_T)
# 転置されたデータに対する階層クラスタリング
dat_T <- t(dat)
dat_T_scaled <- scale(dat_T)
result_T <- agnes(x = dat_T_scaled,
metric = "euclidean",
method = "ward")
par(family = "ヒラギノ角ゴシック W3")
dend_T <- as.dendrogram(result_T)
plot(dend_T, main = "職業印象（Ward法）")
dend_average <- as.dendrogram(result_average)
plot(dend_average, main = "職業印象（群平均法）")
dend_T <- as.dendrogram(result_T)
plot(dend_T, main = "職業印象（Ward法）")
?color_branches
?color_branch
?color_branches
??color_branches
# フラットクラスタリング
# - 教科書では「スライス」すると表現されている。
flat_clustering <- color_branches(dend_ward, k = 4)
View(iris)
library(dendrextend)
library(dendextend)
install.packages("dendextend")
library(dendextend)
# フラットクラスタリング
# - 教科書では「スライス」すると表現されている。
flat_clustering <- color_branches(dend_ward, k = 4)
dend_ward <- as.dendrogram(result_ward)
plot(dend_ward, main = "職業印象（Ward法）")
###### 階層クラスタリング : Ward法 #####
# 教科書と結果が異なる。
# - 正規化するかしないかで結果が異なったわけではない。
result_ward <- agnes(x = dat_scaled,
metric = "euclidean",
method = "ward")
dend_ward <- as.dendrogram(result_ward)
plot(dend_ward, main = "職業印象（Ward法）")
# フラットクラスタリング
# - 教科書では「スライス」すると表現されている。
flat_clustering <- color_branches(dend_ward, k = 4)
plot(flat_clustering)
# フラットクラスタリング
# - 教科書では「スライス」すると表現されている。
flat_clustering <- color_branches(dend_ward, h = 5)
plot(flat_clustering), main = "フラットクラスタリング")
plot(flat_clustering, main = "フラットクラスタリング")
cluster <- cutree(dend_ward, h = 5)
cluster
cluster_id <- cutree(dend_ward, h = 5)
cluster_id
##### 発展的な話題 #####
# 遺伝統計学では、次のようにヒートマップと一緒にデンドログラムをかくことがある。
heatmap(x = dat_scaled,
hclustfun = function (x) {agnes(x,
metric = "euclidean",
method = "ward")})
?heatmap
##### ライブラリの読み込み #####
library(cluster)
library(dendextend)
par(family = "ヒラギノ角ゴシック W3")    # Macユーザーのみ
###### データの読み込み #####
dat <- read.csv("impression.csv",
fileEncoding = "Shift-JIS",
row.names = "職業")
dat
summary(dat)
dat_scaled
summary(dat_scaled)
var(dat_scaled)
###### 階層クラスタリング : Ward法 #####
# 教科書と結果が異なる。
# - 正規化するかしないかで結果が異なったわけではない。
result_ward <- agnes(x = dat_scaled,
metric = "euclidean",    # p.12の距離に書かれている式のこと
method = "ward")    # p.15の2.4で説明されていること
dend_ward <- as.dendrogram(result_ward)
plot(dend_ward, main = "職業印象（Ward法）")
# フラットクラスタリング
# - 2.3節「デンドログラムの利用」
# - 教科書では「スライス」すると表現されている。
flat_clustering <- color_branches(dend_ward, h = 5)
plot(flat_clustering, main = "フラットクラスタリング")
cluster_id <- cutree(dend_ward, h = 5)
cluster_id
dat[cluster_id == 1, ]
summary(dat[cluster_id == 1, ])
library(ggplot2)
ggdat <- dat
ggdat$cluster <- cluster_id
ggplot(data = ggdat,
mapping = aes(x = cluster, y = 立派な)) +
geom_boxplot()
ggplot(data = ggdat,
mapping = aes(x = as.character(cluster), y = 立派な)) +
geom_boxplot()
dat[cluster_id == 2, ]
dat[cluster_id == 3, ]
dat[cluster_id == 4, ]
dat[cluster_id == 1, ]
ggplot(data = ggdat,
mapping = aes(x = as.character(cluster), y = 立派な)) +
geom_boxplot() +
theme_gray(base_family = "ヒラギノ角ゴシック W3")
ggplot(data = ggdat,
mapping = aes(x = as.character(cluster), y = 立派な)) +
geom_boxplot() +
theme_gray(base_family = "ヒラギノ角ゴシック W3") +
xlab("クラスター id")
ggplot(data = ggdat,
mapping = aes(x = cluster, y = 立派な)) +
geom_boxplot() +
theme_gray(base_family = "ヒラギノ角ゴシック W3") +
xlab("クラスター id")
ggplot(data = ggdat,
mapping = aes(x = as.character(cluster), y = 立派な)) +
geom_boxplot() +
theme_gray(base_family = "ヒラギノ角ゴシック W3") +
xlab("クラスター id")
ggplot(data = ggdat,
mapping = aes(x = as.factor(cluster), y = 立派な)) +
geom_boxplot() +
theme_gray(base_family = "ヒラギノ角ゴシック W3") +
xlab("クラスター id")
##### 発展的な話題 #####
# 遺伝統計学では、次のようにヒートマップと一緒にデンドログラムをかくことがある。
# 遺伝子発現行列の可視化という意味合いを持っている。
heatmap(x = dat_scaled,
hclustfun = function (x) {agnes(x,
metric = "euclidean",
method = "ward")},
main = "ヒートマップ")
library(forecast)
library(forecast)
cabbage <- read.csv("cabbage.csv")
setwd("~/Desktop/すうがくぶんか/集団授業/時系列の数理/lecture16")
library(forecast)
cabbage <- read.csv("cabbage.csv")
library(forecast)
cabbage <- read.csv("./data/cabbage.csv")
tail(cabbage)
ts_cabbage<-ts(cabbage$cabbage, frequency = 12)
# 折れ線グラフ
ggtsdisplay(ts_cabbage)
# periodogram
ggtsdisplay(ts_cabbage, plot.type = "spectrum")
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(0, 0, 2))
sarima_200_002_12
# 残差の折れ線グラフ
ggtsdisplay(sarima_200_002_12$residuals, plot.type = "histogram")
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_100_002_12 <- Arima(ts_cabbage,
order = c(1, 0, 0),
seasonal = c(0, 0, 2))
sarima_100_002_12
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(2, 0, 0))
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(2, 0, 0))
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(0, 0, 2))
sarima_200_002_12
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(2, 0, 0))
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(0, 0, 2))
sarima_200_002_12
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(1, 0, 2))
sarima_200_002_12
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(2, 0, 2))
#### C1. ${\rm SARIMA}(2,0,0)(0,0,2)_{12}$の推定
sarima_200_002_12 <- Arima(ts_cabbage,
order = c(2, 0, 0),
seasonal = c(1, 0, 2))
sarima_200_002_12
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 2,
seasonal = TURE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 2,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 3, max.D = 1, max.Q = 3,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 3, max.D = 1, max.Q = 3,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 2,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 2,
seasonal = TRUE, stationary = TRUE)
# 残差の折れ線グラフ
ggtsdisplay(sarima_200_002_12$residuals, plot.type = "histogram")
# ${\rm SARIMA}(1,0,1)(2,0,0)_{12}$の推定
sarima_101_200_12 <- Arima(ts_cabbage,
order = c(1, 0, 1),
seasonal = c(2, 0, 0))
sarima_101_200_12
# 残差の折れ線グラフ
ggtsdisplay(sarima_101_200_12$residuals, plot.type = "histogram")
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 3, max.D = 1, max.Q = 2,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 4, max.D = 1, max.Q = 2,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 2,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 3,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 4,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 5,
seasonal = TRUE, stationary = TRUE)
auto.arima(y = ts_cabbage,
max.p = 2, max.d = 1, max.q = 2,
max.P = 2, max.D = 1, max.Q = 2,
seasonal = TRUE, stationary = TRUE)
View(x)
predict(sarima_101_200_12, h = 12)
plot(predict(sarima_101_200_12, h = 12))
plot(forecast(sarima_101_200_12, h = 12))
plot(forecast(sarima_101_200_12, h = 144))
plot(forecast(sarima_101_200_12, h = 120))
# 折れ線グラフ
ggtsdisplay(log(ts_cabbage))
# 折れ線グラフ
ggtsdisplay(diff(ts_cabbage))
# 折れ線グラフ
ggtsdisplay(ts_cabbage)
p21<-cbind(rnorm(n=25,mean=1,sd=1),rnorm(n=25,mean=1,sd=1))
p22<-cbind(rnorm(n=25,mean=-1,sd=1),rnorm(n=25,mean=1,sd=1))
p23<-cbind(rnorm(n=25,mean=-1,sd=1),rnorm(n=25,mean=-1,sd=1))
p24<-cbind(rnorm(n=25,mean=1,sd=1),rnorm(n=25,mean=-1,sd=1))
t<-as.factor(c(rep(0,50),rep(1,50)))
d2<-as.data.frame(cbind(rbind(p21,p23,p22,p24),t))
names(d2)<-c("x1","x2","y")
d2
plot(d2)
plot(d2$x1, d2$x2, col = d2$y)
p21<-cbind(rnorm(n=75,mean=1,sd=1),rnorm(n=75,mean=1,sd=1))
p21<-cbind(rnorm(n=75,mean=1,sd=1),rnorm(n=75,mean=1,sd=1))
p21<-cbind(rnorm(n=75,mean=1,sd=1),rnorm(n=75,mean=1,sd=1))
p22<-cbind(rnorm(n=75,mean=-1,sd=1),rnorm(n=75,mean=1,sd=1))
p23<-cbind(rnorm(n=75,mean=-1,sd=1),rnorm(n=75,mean=-1,sd=1))
p24<-cbind(rnorm(n=75,mean=1,sd=1),rnorm(n=75,mean=-1,sd=1))
t<-as.factor(c(rep(0,150),rep(1,150)))
d2<-as.data.frame(cbind(rbind(p21,p23,p22,p24),t))
names(d2)<-c("x1","x2","y")
plot(d2$x1, d2$x2, col = d2$y)
p21<-cbind(rnorm(n=75,mean=1,sd=0.5),rnorm(n=75,mean=1,sd=0.5))
p22<-cbind(rnorm(n=75,mean=-1,sd=0.5),rnorm(n=75,mean=1,sd=0.5))
p23<-cbind(rnorm(n=75,mean=-1,sd=0.5),rnorm(n=75,mean=-1,sd=0.5))
p24<-cbind(rnorm(n=75,mean=1,sd=0.5),rnorm(n=75,mean=-1,sd=0.5))
t<-as.factor(c(rep(0,150),rep(1,150)))
d2<-as.data.frame(cbind(rbind(p21,p23,p22,p24),t))
names(d2)<-c("x1","x2","y")
plot(d2$x1, d2$x2, col = d2$y)
p21<-cbind(rnorm(n=75,mean=1,sd=0.75),rnorm(n=75,mean=1,sd=0.75))
p22<-cbind(rnorm(n=75,mean=-1,sd=0.75),rnorm(n=75,mean=1,sd=0.75))
p23<-cbind(rnorm(n=75,mean=-1,sd=0.75),rnorm(n=75,mean=-1,sd=0.75))
p24<-cbind(rnorm(n=75,mean=1,sd=0.75),rnorm(n=75,mean=-1,sd=0.75))
t<-as.factor(c(rep(0,150),rep(1,150)))
d2<-as.data.frame(cbind(rbind(p21,p23,p22,p24),t))
names(d2)<-c("x1","x2","y")
plot(d2$x1, d2$x2, col = d2$y)
p21<-cbind(rnorm(n=75,mean=1,sd=0.75),rnorm(n=75,mean=1,sd=0.75))
p22<-cbind(rnorm(n=75,mean=-1,sd=0.75),rnorm(n=75,mean=1,sd=0.75))
p23<-cbind(rnorm(n=75,mean=-1,sd=0.75),rnorm(n=75,mean=-1,sd=0.75))
p24<-cbind(rnorm(n=75,mean=1,sd=0.75),rnorm(n=75,mean=-1,sd=0.75))
t<-as.factor(c(rep(0,150),rep(1,150)))
d2<-as.data.frame(cbind(rbind(p21,p23,p22,p24),t))
names(d2)<-c("x1","x2","y")
plot(d2$x1, d2$x2, col = d2$y)
?write.csv
write.csv(x = d2, file = "xor_demo_train.csv", row.names = FALSE)
setwd("~/Desktop/すうがくぶんか/集団授業/続初級統計学_改訂/lecture16")
p21<-cbind(rnorm(n=25,mean=1,sd=0.75),rnorm(n=25,mean=1,sd=0.75))
p22<-cbind(rnorm(n=25,mean=-1,sd=0.75),rnorm(n=25,mean=1,sd=0.75))
p23<-cbind(rnorm(n=25,mean=-1,sd=0.75),rnorm(n=25,mean=-1,sd=0.75))
p24<-cbind(rnorm(n=25,mean=1,sd=0.75),rnorm(n=25,mean=-1,sd=0.75))
t<-as.factor(c(rep(0,50),rep(1,50)))
d2<-as.data.frame(cbind(rbind(p21,p23,p22,p24),t))
names(d2)<-c("x1","x2","y")
plot(d2$x1, d2$x2, col = d2$y)
write.csv(x = d2, file = "xor_demo_test.csv", row.names = FALSE)
dat <- read.csv("./data/xor_demo_train.csv",
fileEncoding = "utf-8")
dat$y <- as.factor(dat$y)
head(x = dat, n = 5)
plot(dat$x1, dat$x2, col = dat$y)
install.packages("kernlab")
library(kernlab)
?ksvm
library(kernlab)
result <- ksvm(formula = y ~ x1 + x2,
data = dat,
type = "C-svc",
C = 1.0
kernel = "rbfdot",
library(kernlab)
result <- ksvm(formula = y ~ x1 + x2,
data = dat,
type = "C-svc",
C = 1.0,
kernel = "rbfdot",
kpar = list(sigma = 1.0))
train <- read.csv("./data/xor_demo_train.csv",
fileEncoding = "utf-8")
train$y <- as.factor(train$y)
head(x = train, n = 5)
plot(train$x1, train$x2, col = train$y)
library(kernlab)
result <- ksvm(y ~ x1 + x2,
data = train,
type = "C-svc",
C = 1.0,
kernel = "rbfdot",
kpar = list(sigma = 1.0))
result
library(kernlab)
result <- ksvm(x = y ~ x1 + x2,
data = train,
type = "C-svc",
C = 1.0,
kernel = "rbfdot",
kpar = list(sigma = 1.0))
result
str(result)
summary(train)
x1_min <- min(train$x1)
x1_max <- max(train$x1)
x2_min <- min(train$x2)
x2_max <- max(train$x2)
x1 <- (train$x1 - x1_min) / (x1_max - x1_min)
x2 <- (train$x2 - x2_min) / (x2_max - x2_min)
train_scaled <- data.frame(x1 = x1, x2 = x2, y = train$y)
head(train_scaled, n = 5)
library(kernlab)
result <- ksvm(x = y ~ x1 + x2,
data = train_scaled,    # 正規化したデータ
type = "C-svc",
C = 1.0,
kernel = "rbfdot",
kpar = list(sigma = 1.0))
result
# メッシュグリッドの作成
xx1 <- seq(-3, 3, 0.05)
xx2 <- seq(-3, 3, 0.05)
meshgrid <- expand.grid(xx1, xx2)
meshgrid
# メッシュグリッドの作成
xx1 <- seq(-3, 3, 0.05)
xx2 <- seq(-3, 3, 0.05)
meshgrid <- expand.grid(xx1, xx2)
name(meshgrid) <- c("x1", "x2")
# メッシュグリッドの作成
xx1 <- seq(-3, 3, 0.05)
xx2 <- seq(-3, 3, 0.05)
meshgrid <- expand.grid(xx1, xx2)
names(meshgrid) <- c("x1", "x2")
head(meshgrid, n = 5)
# メッシュグリッドデータの正規化
x1 <- (meshgrid$x1 - x1_min) / (x1_max - x1_min)
x2 <- (meshgrid$x2 - x2_min) / (x2_max - x2_min)
meshgrid_scaled <- data.frame(x1 = x1, x2 = x2)
head(meshgrid_scaled, n = 5)
# 予測
pred <- predict(result, meshgrid_scaled, type = "vector")
# 予測
pred <- predict(result, meshgrid_scaled, type = "decision")
pred
# 決定関数の計算
pred <- predict(result, meshgrid_scaled, type = "decision")
filled.contour(meshgrid$x1,
meshgrid$x2,
pred)
# 決定関数の計算
pred <- predict(result, meshgrid_scaled, type = "decision")
filled.contour(xx1, xx2, pred)
# 決定関数の計算
pred <- predict(result, meshgrid_scaled, type = "decision")
filled.contour(xx1, xx2,
array(pred, dim = c(length(xx1), length(xx2)))
# 決定関数の計算
pred <- predict(result, meshgrid_scaled, type = "decision")
filled.contour(xx1, xx2,
array(pred, dim = c(length(xx1), length(xx2))
# 決定関数の計算
pred <- predict(result, meshgrid_scaled, type = "decision")
contour(xx1, xx2,
array(pred, dim = c(length(xx1), length(xx2))
# 決定関数の計算
pred <- predict(result, meshgrid_scaled, type = "decision")
contour(xx1, xx2,
array(pred, dim = c(length(xx1), length(xx2)))
# 決定関数の計算
pred <- predict(result, meshgrid_scaled, type = "decision")
contour(xx1, xx2,
array(pred, dim = c(length(xx1), length(xx2))))
# テストデータの読み込み
test <- read.csv("./data/xor_demo_test.csv",
fileEncoding = "utf-8")
test$y <- as.factor(test$y)
head(x = test, n = 5)
# min-max正規化
x1 <- (test$x1 - x1_min) / (x1_max - x1_min)
x2 <- (test$x2 - x2_min) / (x2_max - x2_min)
test_scaled <- data.frame(x1 = x1, x2 = x2, y = test$y)
head(test_scaled, n = 5)
?predict.ksvm
pred_test <- predict(result, test_scaled, type = "response")
table(test$y, pred_test)
# 訓練データでの混同行列
pred_train <- predict(result, train_scaled, type = "response")
table(train$y, pred_train)
