# データの読み込み
data("ToothGrowth")
dat <- ToothGrowth
summary(object = dat)    # データの概要を確認する。
ggplot(data = dat,
mapping = aes(x = dose, y = len, colour = supp)) +
geom_point() +
geom_smooth(method = "lm")
# 1. 線形回帰モデル
## 目的変数`len`を説明変数`supp`, `dose`で説明する。
fit_lm <- lm(len ~ supp * dose, data = dat)
tidy(fit_lm)
## 決定係数とAICの確認
metrics <- glance(fit_lm)
print(paste("決定係数 : ", metrics$r.squared), quote = FALSE)
print(paste("AIC : ", metrics$AIC), quote = FALSE)
# 3. 目的変数とは独立な説明変数を加える。
## 新しく加えた説明変数`random`は目的変数の説明に寄与しないはず。
dat_add_random <- dat
dat_add_random$random <- rnorm(n = nrow(dat))
fit_lm_r <- lm(len ~ supp * dose + random, data = dat_add_random)
tidy(fit_lm_r)
## 決定係数とAICの確認
metrics_r <- glance(fit_lm_r)
print(paste("決定係数 : ", metrics_r$r.squared), quote = FALSE)
print(paste("AIC : ", metrics_r$AIC), quote = FALSE)
# 必要なパッケージの読み込み
library(ggplot2)
library(broom)
# データの読み込み
data("ToothGrowth")
dat <- ToothGrowth
summary(object = dat)    # データの概要を確認する。
ggplot(data = dat,
mapping = aes(x = dose, y = len, colour = supp)) +
geom_point() +
geom_smooth(method = "lm")
# 1. 線形回帰モデル
## 目的変数`len`を説明変数`supp`, `dose`で説明する。
fit_lm <- lm(len ~ supp * dose, data = dat)
tidy(fit_lm)
## 決定係数とAICの確認
metrics <- glance(fit_lm)
print(paste("決定係数 : ", metrics$r.squared), quote = FALSE)
print(paste("AIC : ", metrics$AIC), quote = FALSE)
# 3. 目的変数とは独立な説明変数を加える。
## 新しく加えた説明変数`random`は目的変数の説明に寄与しないはず。
dat_add_random <- dat
dat_add_random$random <- rnorm(n = nrow(dat))
fit_lm_r <- lm(len ~ supp * dose + random, data = dat_add_random)
tidy(fit_lm_r)
## 決定係数とAICの確認
metrics_r <- glance(fit_lm_r)
print(paste("決定係数 : ", metrics_r$r.squared), quote = FALSE)
print(paste("AIC : ", metrics_r$AIC), quote = FALSE)
metrics
str(fit_lm)
max(0, 1 - adj_factor * (1 - r2))
# 2. 修正済み決定係数・Cp・AIC・BICの計算
## 準備
n <- nrow(dat)    # サンプルサイズ
# 2. 修正済み決定係数・Cp・AIC・BICの計算
## 準備
n <- nrow(dat)    # サンプルサイズ
# 2. 修正済み決定係数・Cp・AIC・BICの計算
## 準備
n <- nrow(dat)    # サンプルサイズ
p <- ncol(dat) - 1    # 説明変数の個数
r2 <- metrics$r.squared
## 2.1 修正済み決定係数
adj_factor <- (n - 1) / (n - p - 1)
max(0, 1 - adj_factor * (1 - r2))
metrics$adj.r.squared    # 答え合わせ
p <- 3    # 説明変数の個数（交互作用項も数える）
p <- 3    # 説明変数の個数（交互作用項も数える）
r2 <- metrics$r.squared
## 2.1 修正済み決定係数
adj_factor <- (n - 1) / (n - p - 1)
max(0, 1 - adj_factor * (1 - r2))
metrics$adj.r.squared    # 答え合わせ
# 3. 繰り返し実験してみる。
R_squared <- c()
Akaike_IC <- c()
for (i in 1:100) {
dat_add_random <- dat
dat_add_random$random <- rnorm(n = nrow(dat))
fit_lm_r <- lm(len ~ supp * dose + random, data = dat_add_random)
metrics_r <- glance(fit_lm_r)
R_squared[i] <- metrics_r$r.squared
Akaike_IC[i] <- metrics_r$AIC
}
boxplot(R_squared)
boxplot(Akaike_IC)
boxplot(R_squared)
print(paste("決定係数 : ", metrics$r.squared), quote = FALSE)
print(paste("AIC : ", metrics$AIC), quote = FALSE)
boxplot(Akaike_IC)
print(paste("AIC : ", metrics$BIC), quote = FALSE)
# 3. 繰り返し実験してみる。
R_squared <- c()
Akaike_IC <- c()
for (i in 1:100) {
dat_add_random <- dat
dat_add_random$random <- rnorm(n = nrow(dat))
fit_lm_r <- lm(len ~ supp * dose + random, data = dat_add_random)
metrics_r <- glance(fit_lm_r)
R_squared[i] <- metrics_r$r.squared
Akaike_IC[i] <- metrics_r$BIC
}
boxplot(Akaike_IC)
1 - (10/6)*0.3
1 - (10/5)*0.3
library(broom)
x <- 1:10
y <- 0.1 + 0.2*x + rnorm(10)
res <- lm(y ~ x)
tidy(res)
65^2
35^2
library(broom)
x <- 1:10
y <- 0.1 + 0.2*x + rnorm(10)
res <- lm(y ~ x)
tidy(res)
resid <- (y - predict(res, x))
predict(res)
sigma_u / sum((x-mean(x))^2)
sigma_u <- (y - predict(res))^2 / (10-2)
sigma_u / sum((x-mean(x))^2)
sigma_u <- sum((y - predict(res))^2) / (10-2)
sigma_u <- sum((y - predict(res))^2) / (10-2)
sigma_u / sum((x-mean(x))^2)
tidy(res)
sigma_u <- sum((y - predict(res))^2) / 10
sigma_u / sum((x-mean(x))^2)
library(broom)
x <- 1:10
y <- 0.1 + 0.2*x + rnorm(10)
res <- lm(y ~ x)
tidy(res)
sigma_u <- sum((y - predict(res))^2) / (10-2)
sigma_u / sum((x-mean(x))^2)
sqrt(sigma_u / sum((x-mean(x))^2))
x <- 1:10
y <- 0.1 + 0.2*x + rnorm(10)
x
y
res <- lm(y ~ x)
tidy(res)
sigma_u <- sum((y - predict(res))^2) / (10-2)
sqrt(sigma_u / sum((x-mean(x))^2))
install.packages("kerasR")
library(kerasR)
library(reticulate)
library(kerasR)
(40*275*305*10)/(315^2*314)
(5-1.2698)/1.076817
exp((5-1.2698)/1.076817)
2.6/sqrt(2.925*(1/4+1/4))
2.6/sqrt(2.925*(1/5+1/5))
(4*3.2+4*2.65)/8
2.6/sqrt(2.925*(1/5+1/5))
(4*3.2^2+4*2.65^2)/8
2.6/sqrt(8.63125*(1/5+1/5))
log(1/9)
0.121 * 2 - 13.6 * 0.66 + 0.02 * 50 - 0.87
0.25 + 1.96*sqrt(0.25*0.75/600)
0.25 - 1.96*sqrt(0.25*0.75/600)
power.prop.test(p1 = 0.01, p2 = 0.02, sig.level = 0.05,
power = 0.8, alternative = "one.sided")
install.packages("torch")
torch_tensor(1)
library(torch)
torch_tensor(1)
install.packages("torchvision")
library(torchvision)
library(torch)
library(torch)
library(torchvision)
train_ds <- kmnist_dataset(
".",
download = TRUE,
train = TRUE,
transform = transform_to_tensor
)
install.packages("torchvision")
remotes::install_github("mlverse/torchvision")
libary(torch)
train_ds <- kmnist_dataset(
".",
download = TRUE,
train = TRUE,
transform = transform_to_tensor
)
library(torch)
library(torchvision)
train_ds <- kmnist_dataset(
".",
download = TRUE,
train = TRUE,
transform = transform_to_tensor
)
test_ds <- kmnist_dataset(
".",
download = TRUE,
train = FALSE,
transform = transform_to_tensor
)
train_ds[1]
train_ds[1][[1]]$size()
sqrt(2/3)
-(3/5)^3+2*3/5-1
(sqrt(5)-1)/2
data(diabetes)
library(mclust)
data(diabetes)
diabetes
write.csv("diabetes.csv", row.names = FALSE)
write.csv(diabetes, "diabetes.csv", row.names = FALSE)
getwd()
library(mclust)
data(diabetes)
?diabetes
diabetes
library(nomclust)
data(data20)
eskin(data20)
n <-100
prb <- 0.9
muk <- 1.5
clusid <- rep(1:4, each = n)
x1 <- sample(c("A","B"), 2*n, replace = TRUE, x1 <- c(x1, sample(c("A","B"), 2*n, replace = x1 <- as.factor(x1)
x2 <- sample(c("A","B"), 2*n, replace = TRUE, x2 <- c(x2, sample(c("A","B"), 2*n, replace = x2 <- as.factor(x2)
prob = c(prb, 1-prb))
TRUE, prob = c(1-prb, prb)))
prob = c(prb, 1-prb))
TRUE, prob = c(1-prb, prb)))
x3 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk)) x4 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
install.packages("clustMixType")
library(clustMixType)
?clprofiles
n   <- 100
prb <- 0.9
muk <- 1.5
clusid <- rep(1:4, each = n)
x1 <- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 <- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 <- as.factor(x1)
x2 <- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 <- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 <- as.factor(x2)
x3 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x <- data.frame(x1,x2,x3,x4)
x
n   <- 10
prb <- 0.9
muk <- 1.5
clusid <- rep(1:4, each = n)
x1 <- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 <- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 <- as.factor(x1)
x2 <- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 <- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 <- as.factor(x2)
x3 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x <- data.frame(x1,x2,x3,x4)
x
n   <- 10
prb <- 0.8
muk <- 1.5
clusid <- rep(1:4, each = n)
x1 <- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 <- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 <- as.factor(x1)
x2 <- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 <- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 <- as.factor(x2)
x3 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 <- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x <- data.frame(x1,x2,x3,x4)
x
write.csv(x, "data01.csv", row.names = FALSE)
kpres <- kproto(x, 4)
clprofiles(kpres, x)
kpres <- kproto(x, 2, lambda = 0.1)
clprofiles(kpres, x)
?clprofiles
1-0.95^126
?lda
library(MASS)
?lda
b
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
train <- sample(1:150, 75)
table(Iris$Sp[train])
## your answer may differ
##  c  s  v
## 22 23 30
z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train)
z
summary(lda)
str(lda)
summary(z)
str(z)
predict(z, Iris[-train, ])
View(kpres)
pi/3+sqrt(3)/2
sqrt(3)
1/2*log(1/2)+1/2*log(1/2)
3/4*log(3/4)+1/4*log(1/4)
2/5*log(2/5)+3/5*log(3/5)
1/5*log(1/5)+4/5*log(4/5)
log(2)
0.613/0/693
0.613/0.693
0.500/0.693
(0.855+0.722)/2
library(numclust)
x <- c(1, 1, 1, 2, 2, 2)
y <- c(1, 2, 2, 2, 2, 2)
dat <- data.frame(x, y)
ve(dat)
VE(dat)
library(nomclust)
x <- c(1, 1, 1, 2, 2, 2)
y <- c(1, 2, 2, 2, 2, 2)
dat <- data.frame(x, y)
ve(dat)
x <- c(1, 2, 1, 2, 1, 2)
y <- c(1, 1, 2, 2, 3, 3)
dat <- data.frame(x, y)
eskin(dat)
n<-c(1,2,3,4,5)
(1+1/n)^n
exp(pi/4)
sqrt(2)/2*1/(2.193)
sqrt(2)/2*1/(2.193^5)
3^20
for(i in 1:20){3^i}
for(i in 1:20){print(3^i)}
3^10
3^10%125
3^10/125
3^10%%125
3^20%%125
3^25%%125
3^50%%125
3^100%%125
3^99%%125
x <- 3
for (n in 1:100){
print(n)
print(x^n%%125)
x <- x%%100
}
x <- 3
for (n in 1:100){
print(n)
print(x%%125)
x <- 3*x%%100
}
76*3
76*3%125
76*3%%125
(76*3)%%125
x <- 3
for (n in 1:100){
print(n)
print(x%%125)
x <- (3*x)%%100
}
3^40
x <- 3
for (n in 1:40){
print(n)
print(x)
x <- (3*x)%%1000
}
x <- 7
for (n in 1:100){
print(n)
print(x)
x <- (7*x)%%10000
}
x <- 3
for (n in 1:20){
print(n)
print(x)
x <- (3*x)%%1000
}
x <- 3
for (n in 1:60){
print(n)
print(x)
x <- (3*x)%%1000
}
x <- 3
for (n in 1:100){
print(n)
print(x)
x <- (3*x)%%1000
}
x <- 3
for (n in 1:100){
print(n)
print(x%%125)
x <- (3*x)%%1000
}
1 - 292.4/689.7
1 - 292.4^2/689.7^2
1 - 292.4^2*16/17/(689.7^2*11/17)
1 - (292.4^2*16/17)/(689.7^2*11/17)
1 - 292.4/689.7
1 - 292.4^2/689.7^2
1 - (292.4^2*11/17)/(689.7^2*16/17)
ToothGrowth
res <- lm(len ~ VC + dose, data = ToothGrowth)
res <- lm(len ~ vc + dose, data = ToothGrowth)
res <- lm(len ~ supp + dose, data = ToothGrowth)
summary(res)
summary(res)
res <- lm(len ~ 1, data = ToothGrowth)
summary(res)
1675*(0.533+0.181)
50*0.48
prop.test(c(24, 1196), c(50, 1675))
library(pwr)
install.packages("pwr")
library(pwr)
?pwr.2p2n.test
pwer.2p2n.test(h = 0.2, n1 = 50, n2 = 1675, sig.level = 0.05)
pwr.2p2n.test(h = 0.2, n1 = 50, n2 = 1675, sig.level = 0.05)
pwr.2p2n.test(h = 0.2, n1 = 50, n2 = 1675, sig.level = 0.05, alternative = "greater")
pwr.2p2n.test(h = 0.2, n1 = 50, n2 = 1675, sig.level = 0.1, alternative = "greater")
pwr.2p2n.test(h = 0.2, n1 = 50, n2 = 1675, sig.level = 0.1, alternative = "two.sided")
pwr.2p2n.test(h = 0.8, n1 = 50, n2 = 1675, sig.level = 0.1, alternative = "two.sided")
pwr.2p2n.test(h = 0.5, n1 = 50, n2 = 1675, sig.level = 0.1, alternative = "two.sided")
2*arcsin(0.7)-2*arcsin(0.5)
2*asin(0.7)-2*asin(0.5)
3.7714/0.14486
-3.7714+0.14486*30
exp(0.28972)
-2.37766-0.06777+0.69531+0.87194
1/(1+e^(-0.87818))
1/(1+exp(-0.87818))
1/(1+exp(0.87818))
(log(20)-log(18))/sqrt(1/10+1/12)
x <- c(15,13,15,16,14,18,17,16,15,18,19,16,17,18,17,15,16)
length(x)
sum((x-mean(x))^2)
# keiyakuデータセットの確認
dat <- read.csv("./data/keiyaku.csv",
row.names = "会社",
fileEncoding = "cp932")
head(dat, n = 5)
# 標本サイズ、次元、変数の名前の確認
str(dat)
# ロジスティック関数
logistic <- function(x){return(1.0/(1.0+exp(-x)))}
curve(logistic, from = -3.0, to = 3.0)
# 最尤推定
lik <- function(x){return(x^3*(1-x)^2)}
curve(lik, from = 0.0, to = 1.0)
# 訪問時刻と契約結果の間の関係
table(dat$訪問時刻, dat$契約結果)
# 担当者年齢と契約結果の間の関係 : 線形性が確認できる。
par(family = "ヒラギノ角ゴシック W3")
plot(dat$担当者年齢, dat$契約結果)
# ロジスティック回帰
result <- glm(契約結果 ~ 訪問時刻 + 担当者年齢,
family = "binomial"
data = dat)
# ロジスティック回帰
result <- glm(契約結果 ~ 訪問時刻 + 担当者年齢,
family = "binomial",
data = dat)
summary(result)
# 訪問時刻を抜いたモデル
result2 <- glm(契約結果 ~ 担当者年齢,
family = "binomial",
data = dat)
summary(result2)
exp(0.26)
# モデル比較
AIC(result); AIC(result2)
dat <- read.csv("./data/scores.csv", fileEncoding = "utf-8")
setwd("~/Desktop/すうがくぶんか/集団授業/続初級統計学_改訂/lecture05")
dat <- read.csv("./data/scores.csv", fileEncoding = "utf-8")
dat <- read.csv("./data/scores.csv", fileEncoding = "utf-8")
dat
cov(dat)
cor(dat)
# データの読み込み
dat <- read.csv("./data/scores.csv", fileEncoding = "utf-8")
dat
# 分散共分散行列
cov(dat)
# 相関行列
cor(dat)
# 分散共分散行列
cov(dat)
# データの読み込み
dat <- read.csv("./data/scores.csv", fileEncoding = "utf-8")
dat
# 相関行列
cor(dat)
A <- matrix(c(3, 1,
1, 2), nrow = 2, byrow = TRUE)
eigen(A)
